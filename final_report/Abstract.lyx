#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayesian Optimisation using Neural Networks
\end_layout

\begin_layout Author
Devang Agrawal (Queens')
\end_layout

\begin_layout Section*
Technical Abstract
\end_layout

\begin_layout Standard
Bayesian optimisation is an effective methodology for the global optimisation
 of functions with expensive evaluations.
 For instance, while designing robotic gaits, we may want to optimise the
 function from the parameters of the robot gait to the speed of the robot.
 Each function evaluation involves running a physical experiment on the
 robot which could involve a lot of human effort.
 Bayesian optimisation allows us to decide which experiment to run next,
 utilising all the information from previous function evaluations.
 
\end_layout

\begin_layout Standard
Bayesian optimisation relies on querying a physical distribution over functions
 defined by a relatively cheap surrogate model.
 An accurate model for this distribution over functions is critical to the
 effectiveness of the approach and is typically fit using Gaussian processes
 (GPs).
 However GPs can only model a limited set of functions well, scaling them
 to deal with higher dimensional functions is also very challenging.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout

\lang british
ask what other GP limitations.
 High dimensional
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this project, we explore the use of Bayesian neural networks as an alternativ
e to GPs to model the distribution over functions.
 Bayesian neural networks define more flexible priors on functions and can
 potentially be extended to high dimensional problems.
 It is also possible to use Bayesian neural networks (BNNs) with non-Gaussian
 priors (such as Cauchy) on its parameters to model non-smooth functions.
 
\end_layout

\begin_layout Standard
We compare the performance of this BNN based model for Bayesian optimisation
 to one using a GP based model.
 The BNN based model performs competitively with state-of-the-art GP based
 approaches.
 
\end_layout

\end_body
\end_document
