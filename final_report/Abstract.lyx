#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayesian Optimisation using Neural Networks
\end_layout

\begin_layout Author
Devang Agrawal (Queens')
\end_layout

\begin_layout Section*
Technical Abstract
\end_layout

\begin_layout Standard
Bayesian optimisation is an effective methodology for the global optimisation
 of black-box functions with expensive evaluations.
 For instance, while designing robotic gaits, we may want to optimise the
 function from the parameters of the robot gait, to the speed of the robot.
 Each function evaluation involves running a physical experiment on the
 robot which could involve a significant human effort.
 Bayesian optimisation is very useful in such sequential decision making
 tasks and allows us to decide which experiment to run next, utilising all
 the information from previous function evaluations.
 
\end_layout

\begin_layout Standard
Bayesian optimisation relies on querying a distribution over functions defined
 by a relatively cheap surrogate model.
 An accurate model for this distribution over functions is critical to the
 effectiveness of the approach and is typically fit using Gaussian processes
 (GPs).
 However GPs can only model a limited set of functions well, scaling them
 to deal with higher dimensional functions is also very challenging.
 Moreover, GPs scale cubically with observations, making it very challenging
 to optimise functions whose optimisation requires a large number of function
 evaluations.
 Such functions are especially likely in high dimensional problems where
 a significant amount of exploration might be needed to optimise the given
 function.
 
\end_layout

\begin_layout Standard
In this project, we explore the use of Bayesian neural networks as an alternativ
e to GPs to model the distribution over functions.
 Bayesian neural networks define more flexible priors on functions and can
 potentially be extended to high dimensional problems.
 It is also possible to use Bayesian neural networks (BNNs) with non-Gaussian
 priors (such as the Cauchy distribution) on its parameters to model non-smooth
 functions.
 This model also scales linearly with the number of observations which can
 allow it to optimise functions whose optimisation requires a large number
 of evalutations.
 
\end_layout

\begin_layout Standard
We compare the performance of this BNN based model for Bayesian optimisation
 to one using a GP based model.
 The BNN based model performs competitively with state-of-the-art GP based
 approaches.
 
\end_layout

\end_body
\end_document
