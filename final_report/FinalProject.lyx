#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass IIBproject
\use_default_options true
\begin_modules
eqs-within-sections
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayesian Optimisation using Neural Networks
\end_layout

\begin_layout Author
Devang Agrawal (Queens')
\end_layout

\begin_layout Project Group
F-
\end_layout

\begin_layout Summary
This project explored the use of neural networks for Bayesian Optimisation.
 No more than 100 words.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Bayesian Optimisation is a very interesting problem.
 It has been used in ..
 .
 Neural networks can be used for dimensionality reduction and can be used
 for feature selection.
 It is not trivial how to build probabilitic models using Neural Networks.
 Several different options are available and two particualat ones were explored
 in this report.
 Using a pragamatic approach ....
 .
 Alternatively a full Bayesian Neural network was used ....
 .
 These functions can be very useful for non-stationary functions.
\end_layout

\begin_layout Section
Markov Chain Monte Carlo methods
\end_layout

\begin_layout Standard
Markov chain Monte Carlo(MCMC) methods are a class of algorithms for sampling
 from a desired probability distribution
\begin_inset CommandInset citation
LatexCommand cite
key "andrieu2003introduction,neal1996bayesian"

\end_inset

.
 A markov chain is constructed with the desired distribution as its equilibrium
 distribution.
 These models are widely applied to Bayesian models in statistics.
 MCMC methods make no assumtions about the about the form of the underlying
 distribution.
 In theory they can take account of multiple modes and the possibility that
 the main contribution to the integral may come from areas not in the vicinity
 of any mode.
 In practise though it can under certain circumstances they can take a very
 long time to converge to the desired distribution.
 This is the main disadvantage of using MCMC methods.
 
\end_layout

\begin_layout Standard
In Bayesian learning we often encounter situations where we need to evaluate
 the expectation of a function 
\begin_inset Formula $f(\theta)$
\end_inset

 with respect to the posterior probability density of the model parameters.
 Writing the posterior as 
\begin_inset Formula $Q(\theta)$
\end_inset

 , the expectation can be expressed as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E[f]\;=\;\intop f(\theta)Q(\theta)d\theta
\end{equation}

\end_inset

Such expectations can be estimated by the 
\emph on
Monte Carlo 
\emph default
method, using a sample of values from 
\begin_inset Formula $Q$
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E[f]\;\thickapprox\;\frac{1}{N}\sum_{t=1}^{N}f(\theta^{(t)})\label{eq:carloIntegration}
\end{equation}

\end_inset

where 
\begin_inset Formula $\theta^{(1)},\dots,\theta^{(N)}$
\end_inset

 are generated by a process that results in each of them having the distribution
 defined by 
\begin_inset Formula $Q$
\end_inset

.
 In simple Monte Carlo methods, the 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 are independent, however when 
\begin_inset Formula $Q$
\end_inset

 is a complicated distribution , generating such independent values is often
 infeasible.
 However it is often possible to generate a series of dependent values.
 The Monte Carlo integration formula of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:carloIntegration"

\end_inset

) still gives an unbiased estimate of 
\begin_inset Formula $E[f]$
\end_inset

 even when the 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 are dependent as long as the independence is not too great
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 The estimate will still converge to the true value as N increases.
 
\end_layout

\begin_layout Standard
Such a series of dependent values can be generated using a 
\emph on
Markov Chain
\emph default
 that has 
\begin_inset Formula $Q$
\end_inset

 as its stationary distribution.
 The chain can be defined by giving an 
\emph on
initial distribution
\emph default
 for the first state of the chain, 
\begin_inset Formula $\theta^{(1)}$
\end_inset

, and a set of 
\emph on
transition probabilities 
\emph default
for a new state, 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

, to follow the current state, 
\begin_inset Formula $\theta^{(t)}.$
\end_inset

 The probability densities for these transitions can be written as 
\begin_inset Formula $T(\theta^{(t+1)}|\theta^{(t)})$
\end_inset

.
 A 
\emph on
stationary (or invariant)
\emph default
 distribution, 
\begin_inset Formula $Q$
\end_inset

, is one that persists once it is established.
 This means that if 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 has the distribution 
\begin_inset Formula $Q$
\end_inset

, then 
\begin_inset Formula $\theta^{(t')}$
\end_inset

 will have the same distribution for all 
\begin_inset Formula $t'>t$
\end_inset

.
 This invariance condition can be written as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Q(\theta')=\int T(\theta'|\theta)Q(\theta)d\theta
\end{equation}

\end_inset

The invariance with respect to 
\begin_inset Formula $Q$
\end_inset

 is implied by the stronger 
\emph on
detailed balance
\emph default
 condition -- that for all 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $\theta'$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T(\theta'|\theta)Q(\theta)=T(\theta|\theta')Q(\theta')\label{eq:deTAILed balance}
\end{equation}

\end_inset

A chain staisfying detailed balance is said to be 
\emph on
reversible.
\end_layout

\begin_layout Standard
An 
\emph on
ergodic 
\emph default
Markov chain has a unique invariant equilibrium distribution, to which it
 converges from any initial state.
 If we can find a Markov Chain that has 
\begin_inset Formula $Q$
\end_inset

 as its equilibrium distribution, then we can find find expectations with
 respect to 
\begin_inset Formula $Q$
\end_inset

 by using equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:carloIntegration"

\end_inset

) .
 In this case 
\begin_inset Formula $\theta^{(1)},\dots,\theta^{(N)}$
\end_inset

 are the states of the chain, some of the early states can be discarded
 since they are not representative of the equilibrium distribution.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In summary ?
\end_layout

\end_inset

To use MCMC methods to estimate an expectation with respect to some distribution
 
\begin_inset Formula $Q$
\end_inset

, we need to construct an ergodic Markov chain with 
\begin_inset Formula $Q$
\end_inset

 as the equilibrium distribution.
 The chain should rapidly converge to this distribution and the states visited
 once equilibrium is reached should not be highly dependent.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Page 25 maybe write more
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The Metropolis algorithm
\end_layout

\begin_layout Standard
The Metropolis algorithm was introduced by Metropolis et.al in their classic
 paper in 1953
\begin_inset CommandInset citation
LatexCommand cite
key "metropolis1953equation"

\end_inset

 .
 In the Markov chain defined by the metropolis algorithm, a new state, 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

, is generated from the previous state, 
\begin_inset Formula $\theta^{(t)}$
\end_inset

, by first generating a 
\emph on
candidate state 
\emph default
using a specified 
\emph on
proposal distribution, 
\emph default
and then deciding whether or not to accept that state based on its probability
 density relative to the old state, with respect to the desired invariant
 distribution, 
\begin_inset Formula $Q.$
\end_inset

 If accepted, the candidate state, becomes the next state of the Markov
 chain; if it is instead rejected, the new state remains the same as the
 old state.
 
\end_layout

\begin_layout Standard
In detail, the transition from 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 to 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

 is defined as follows:
\end_layout

\begin_layout Enumerate
Generate a candidate state, 
\begin_inset Formula $\theta^{*}$
\end_inset

, from a proposal distribution.
 The proposal distribution may depend on the current state, its density
 is by 
\begin_inset Formula $S(\theta^{*}\,|\,\theta^{(t)})$
\end_inset

.
 It is noted that the proposal distribution must be symmetrical, satisfying
 the condition 
\begin_inset Formula $S(\theta'\,|\,\theta)=S(\theta\,|\,\theta')$
\end_inset

.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $Q(\theta^{*})\geq Q(\theta^{t})$
\end_inset

, accept the candidate state; otherwise accept the candidate state with
 probability 
\begin_inset Formula $Q(\theta')/Q(\theta)$
\end_inset

.
 For 
\begin_inset Formula $\theta'\neq\theta$
\end_inset

, the overall transition probability is then given by:
\begin_inset Formula 
\begin{equation}
T(\theta'|\theta)=S(\theta'\,|\,\theta)min(1,Q(\theta')/Q(\theta))\label{eq:overallTransitionmetropolis}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
If the candidate state is accepted, let 
\begin_inset Formula $\theta^{t+1}=\theta^{*}$
\end_inset

.
 However if it was not accepted, then set 
\begin_inset Formula $\theta^{(t+1)}=\theta^{(t)}$
\end_inset

.
\end_layout

\begin_layout Standard
Following the overall transition probability in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:overallTransitionmetropolis"

\end_inset

), the detailed balance condition (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:deTAILed balance"

\end_inset

) can be verified as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
T(\theta'|\theta)Q(\theta) & =S(\theta'\,|\,\theta)min(1,Q(\theta')/Q(\theta))Q(\theta)\\
 & =S(\theta'\,|\,\theta)min(Q(\theta),Q(\theta'))\\
 & =S(\theta\,|\,\theta')min(Q(\theta'),Q(\theta))\\
 & =S(\theta\,|\,\theta')min(1,Q(\theta)/Q(\theta'))Q(\theta')\\
 & =T(\theta|\theta')Q(\theta')
\end{align*}

\end_inset

Therefore the Metropolis updates leave 
\begin_inset Formula $Q$
\end_inset

 invariant.
 
\end_layout

\begin_layout Standard
Many choices are available for the proposal distribution of the Metropolis
 algorithm.
 One simple and popular choice is a Gaussian distribution centred on 
\begin_inset Formula $\theta^{(t)},$
\end_inset

with the variance chosen so that the probability of the candidate being
 accepted is reasonably high.
 Very low acceptance rates can be bad as they lead to successive samples
 being highly dependent.
 When sampling from a complex, high-dimensional distribution, the standard
 deviation of of the proposal distributions typically has to be very small
 to comapred to the extent of 
\begin_inset Formula $Q.$
\end_inset

 This is because large changes will almost certainly lead to regions of
 low probability.
 A large number of steps will be required to move to a distant point in
 the distribution.
 The problem is made worse by the fact that these movements will take the
 form of a random walk, rather than a systematic traversal.
\end_layout

\begin_layout Standard
Simple forms of the Metropolis algorithm can be very slow when applied to
 problems such as Bayesian learning for neural networks
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 As will be seen 
\begin_inset Note Note
status open

\begin_layout Plain Layout
add correct chapter
\end_layout

\end_inset

 , this problem can be alleviated by using the hybrid Monte Carlo algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "DUANE1987216"

\end_inset

, in which candidate states are generated by a dynamical method which can
 avoid the random walk aspect of the exploration.
\end_layout

\begin_layout Section
Neural Networks
\end_layout

\begin_layout Standard
Neural networks represent multiple non-linear transforms of the input data
\begin_inset CommandInset citation
LatexCommand cite
key "Bengio-et-al-2015-Book"

\end_inset

 .
 Excellent at Feature Selection 
\begin_inset Note Note
status open

\begin_layout Plain Layout
can also use radfords book 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Intriguing properties of Neural Networks 
\end_layout

\begin_layout Standard
Some interesting properties of neural networks have been recently investigated.
 
\end_layout

\begin_layout Section
Bayesian Optimisation
\end_layout

\begin_layout Standard
Bayesian Optimisation is the model based optimisation of black box functions.
 
\end_layout

\begin_layout Subsection
High Dimesnional Bayesian Optimisation 
\end_layout

\begin_layout Standard
An original goal of this project was to explore Bayesian Optimisation in
 high dimensions .
 This has not been thoroghly explored in the available literature.
 However two good papers have tried to tackle this problem.
 
\end_layout

\begin_layout Subsubsection
Rembo
\end_layout

\begin_layout Standard
Developed by Ziyu wang ..
 
\end_layout

\begin_layout Subsubsection
Add-GP-UCB
\end_layout

\begin_layout Standard
Was developed at CMU by ..
\end_layout

\begin_layout Section
Bayesian Optimisation with Neural Networks
\end_layout

\begin_layout Subsection
Using a hybrid model
\end_layout

\begin_layout Standard
A model where the last layer of hidden units are fed to the BLR to obtain
 
\end_layout

\begin_layout Subsubsection
Results 
\end_layout

\begin_layout Subsection
Using a full bayesian neural network
\end_layout

\begin_layout Standard
A full Bayesian neural net 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
add illustration of neural network from neal pg17.
 Prior just show 10 random NN's .
 Then train using HMC then draw 10 randomNN's 
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Markov Chain Monte Carlo methods
\end_layout

\begin_layout Subsubsection
Results 
\end_layout

\begin_layout Subsection
Results and Discussion
\end_layout

\begin_layout Standard
Maybe like this
\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
The results are very promising 
\end_layout

\begin_layout Subsection
Potential applications/Future work
\end_layout

\begin_layout Standard
This system promises to provide better results for high-dimensional functions.
 Add Nileshs paper to this 
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "bibliography"
options "bibtotoc,plain"

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
\start_of_appendix
Risk Assesment Retrospective
\end_layout

\begin_layout Standard
The risk assesment submitted at the start of the project identified frequent
 computer use as the main potential hazard.
 This assessment was accurate and no other hazards were encountered during
 the execution of the project.
 To avoid repetitive stress injury from excessive computer use, frequent
 breaks were taken by the author.
 Several exercises and best practices
\begin_inset CommandInset citation
LatexCommand cite
key "dugan2011healthy"

\end_inset

 were employed to reduce the risk further.
 If the project is to be carried out again, the risk assessment will remain
 the same.
\end_layout

\end_body
\end_document
