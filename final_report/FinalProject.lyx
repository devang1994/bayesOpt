#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass IIBproject
\use_default_options true
\begin_modules
eqs-within-sections
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 0
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayesian Optimisation using Neural Networks
\end_layout

\begin_layout Author
Devang Agrawal (Queens')
\end_layout

\begin_layout Project Group
F-
\end_layout

\begin_layout Summary
This project explored the use of neural networks for Bayesian Optimisation.
 No more than 100 words.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Bayesian Optimisation is a very interesting problem.
 It has been used in ..
 .
 Neural networks can be used for dimensionality reduction and can be used
 for feature selection.
 It is not trivial how to build probabilistic models using Neural Networks.
 Several different options are available and two particular ones were explored
 in this report.
 Using a pragmatic approach ....
 .
 Alternatively a full Bayesian Neural network was used ....
 .
 These functions can be very useful for non-stationary functions.
\end_layout

\begin_layout Section
Neural Networks
\begin_inset CommandInset label
LatexCommand label
name "sec:Neural-Networks"

\end_inset


\end_layout

\begin_layout Standard
Neural networks represent multiple non-linear transforms of the input data
\begin_inset CommandInset citation
LatexCommand cite
key "Bengio-et-al-2015-Book"

\end_inset

 .
 Excellent at Feature Selection 
\begin_inset Note Note
status open

\begin_layout Plain Layout
can also use radfords book 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Markov Chain Monte Carlo methods
\end_layout

\begin_layout Standard
Markov chain Monte Carlo(MCMC) methods are a class of algorithms for sampling
 from a desired probability distribution
\begin_inset CommandInset citation
LatexCommand cite
key "andrieu2003introduction,neal1996bayesian"

\end_inset

.
 A Markov chain is constructed with the desired distribution as its equilibrium
 distribution.
 These models are widely applied to Bayesian models in statistics.
 MCMC methods make no assumptions about the about the form of the underlying
 distribution.
 In theory they can take account of multiple modes and the possibility that
 the main contribution to the integral may come from areas not in the vicinity
 of any mode.
 In practise though it can under certain circumstances they can take a very
 long time to converge to the desired distribution.
 This is the main disadvantage of using MCMC methods.
 
\end_layout

\begin_layout Standard
In Bayesian learning we often encounter situations where we need to evaluate
 the expectation of a function 
\begin_inset Formula $f(\theta)$
\end_inset

 with respect to the posterior probability density of the model parameters.
 Writing the posterior as 
\begin_inset Formula $Q(\theta)$
\end_inset

 , the expectation can be expressed as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E[f]\;=\;\intop f(\theta)Q(\theta)d\theta
\end{equation}

\end_inset

Such expectations can be estimated by the 
\emph on
Monte Carlo 
\emph default
method, using a sample of values from 
\begin_inset Formula $Q$
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E[f]\;\thickapprox\;\frac{1}{N}\sum_{t=1}^{N}f(\theta^{(t)})\label{eq:carloIntegration}
\end{equation}

\end_inset

where 
\begin_inset Formula $\theta^{(1)},\dots,\theta^{(N)}$
\end_inset

 are generated by a process that results in each of them having the distribution
 defined by 
\begin_inset Formula $Q$
\end_inset

.
 In simple Monte Carlo methods, the 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 are independent, however when 
\begin_inset Formula $Q$
\end_inset

 is a complicated distribution , generating such independent values is often
 infeasible.
 However it is often possible to generate a series of dependent values.
 The Monte Carlo integration formula of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:carloIntegration"

\end_inset

) still gives an unbiased estimate of 
\begin_inset Formula $E[f]$
\end_inset

 even when the 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 are dependent as long as the independence is not too great
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 The estimate will still converge to the true value as N increases.
\end_layout

\begin_layout Standard
Such a series of dependent values can be generated using a 
\emph on
Markov Chain
\emph default
 that has 
\begin_inset Formula $Q$
\end_inset

 as its stationary distribution.
 The chain can be defined by giving an 
\emph on
initial distribution
\emph default
 for the first state of the chain, 
\begin_inset Formula $\theta^{(1)}$
\end_inset

, and a set of 
\emph on
transition probabilities 
\emph default
for a new state, 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

, to follow the current state, 
\begin_inset Formula $\theta^{(t)}.$
\end_inset

 The probability densities for these transitions can be written as 
\begin_inset Formula $T(\theta^{(t+1)}|\theta^{(t)})$
\end_inset

.
 A 
\emph on
stationary (or invariant)
\emph default
 distribution, 
\begin_inset Formula $Q$
\end_inset

, is one that persists once it is established.
 This means that if 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 has the distribution 
\begin_inset Formula $Q$
\end_inset

, then 
\begin_inset Formula $\theta^{(t')}$
\end_inset

 will have the same distribution for all 
\begin_inset Formula $t'>t$
\end_inset

.
 This invariance condition can be written as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Q(\theta')=\int T(\theta'|\theta)Q(\theta)d\theta
\end{equation}

\end_inset

The invariance with respect to 
\begin_inset Formula $Q$
\end_inset

 is implied by the stronger 
\emph on
detailed balance
\emph default
 condition -- that for all 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $\theta'$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T(\theta'|\theta)Q(\theta)=T(\theta|\theta')Q(\theta')\label{eq:deTAILed balance}
\end{equation}

\end_inset

A chain satisfying detailed balance is said to be 
\emph on
reversible.
\end_layout

\begin_layout Standard
An 
\emph on
ergodic 
\emph default
Markov chain has a unique invariant equilibrium distribution, to which it
 converges from any initial state.
 If we can find a Markov Chain that has 
\begin_inset Formula $Q$
\end_inset

 as its equilibrium distribution, then we can find find expectations with
 respect to 
\begin_inset Formula $Q$
\end_inset

 by using equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:carloIntegration"

\end_inset

) .
 In this case 
\begin_inset Formula $\theta^{(1)},\dots,\theta^{(N)}$
\end_inset

 are the states of the chain, some of the early states can be discarded
 since they are not representative of the equilibrium distribution.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In summary ?
\end_layout

\end_inset

To use MCMC methods to estimate an expectation with respect to some distribution
 
\begin_inset Formula $Q$
\end_inset

, we need to construct an ergodic Markov chain with 
\begin_inset Formula $Q$
\end_inset

 as the equilibrium distribution.
 The chain should rapidly converge to this distribution and the states visited
 once equilibrium is reached should not be highly dependent.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Page 25 maybe write more
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The Metropolis algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:The-Metropolis-algorithm"

\end_inset


\end_layout

\begin_layout Standard
The Metropolis algorithm was introduced by Metropolis et.al in their classic
 paper in 1953
\begin_inset CommandInset citation
LatexCommand cite
key "metropolis1953equation"

\end_inset

 .
 In the Markov chain defined by the metropolis algorithm, a new state, 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

, is generated from the previous state, 
\begin_inset Formula $\theta^{(t)}$
\end_inset

, by first generating a 
\emph on
candidate state 
\emph default
using a specified 
\emph on
proposal distribution, 
\emph default
and then deciding whether or not to accept that state based on its probability
 density relative to the old state, with respect to the desired invariant
 distribution, 
\begin_inset Formula $Q.$
\end_inset

 If accepted, the candidate state, becomes the next state of the Markov
 chain; if it is instead rejected, the new state remains the same as the
 old state.
 
\end_layout

\begin_layout Standard
In detail, the transition from 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 to 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

 is defined as follows:
\end_layout

\begin_layout Enumerate
Generate a candidate state, 
\begin_inset Formula $\theta^{*}$
\end_inset

, from a proposal distribution.
 The proposal distribution may depend on the current state, its density
 is by 
\begin_inset Formula $S(\theta^{*}\,|\,\theta^{(t)})$
\end_inset

.
 It is noted that the proposal distribution must be symmetrical, satisfying
 the condition 
\begin_inset Formula $S(\theta'\,|\,\theta)=S(\theta\,|\,\theta')$
\end_inset

.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $Q(\theta^{*})\geq Q(\theta^{t})$
\end_inset

, accept the candidate state; otherwise accept the candidate state with
 probability 
\begin_inset Formula $Q(\theta')/Q(\theta)$
\end_inset

.
 For 
\begin_inset Formula $\theta'\neq\theta$
\end_inset

, the overall transition probability is then given by:
\begin_inset Formula 
\begin{equation}
T(\theta'|\theta)=S(\theta'\,|\,\theta)min(1,Q(\theta')/Q(\theta))\label{eq:overallTransitionmetropolis}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
If the candidate state is accepted, let 
\begin_inset Formula $\theta^{t+1}=\theta^{*}$
\end_inset

.
 However if it was not accepted, then set 
\begin_inset Formula $\theta^{(t+1)}=\theta^{(t)}$
\end_inset

.
\end_layout

\begin_layout Standard
Following the overall transition probability in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:overallTransitionmetropolis"

\end_inset

), the detailed balance condition (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:deTAILed balance"

\end_inset

) can be verified as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
T(\theta'|\theta)Q(\theta) & =S(\theta'\,|\,\theta)min(1,Q(\theta')/Q(\theta))Q(\theta)\\
 & =S(\theta'\,|\,\theta)min(Q(\theta),Q(\theta'))\\
 & =S(\theta\,|\,\theta')min(Q(\theta'),Q(\theta))\\
 & =S(\theta\,|\,\theta')min(1,Q(\theta)/Q(\theta'))Q(\theta')\\
 & =T(\theta|\theta')Q(\theta')
\end{align*}

\end_inset

Therefore the Metropolis updates leave 
\begin_inset Formula $Q$
\end_inset

 invariant.
 
\end_layout

\begin_layout Standard
Many choices are available for the proposal distribution of the Metropolis
 algorithm.
 One simple and popular choice is a Gaussian distribution centred on 
\begin_inset Formula $\theta^{(t)},$
\end_inset

with the variance chosen so that the probability of the candidate being
 accepted is reasonably high.
 Very low acceptance rates can be bad as they lead to successive samples
 being highly dependent.
 When sampling from a complex, high-dimensional distribution, the standard
 deviation of of the proposal distributions typically has to be very small
 to compared to the extent of 
\begin_inset Formula $Q.$
\end_inset

 This is because large changes will almost certainly lead to regions of
 low probability.
 A large number of steps will be required to move to a distant point in
 the distribution.
 The problem is made worse by the fact that these movements will take the
 form of a random walk, rather than a systematic traversal.
\end_layout

\begin_layout Standard
Simple forms of the Metropolis algorithm can be very slow when applied to
 problems such as Bayesian learning for neural networks
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 As will be seen in section (
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-hybrid-Monte"

\end_inset

) , this problem can be alleviated by using the hybrid Monte Carlo algorithm
\begin_inset CommandInset citation
LatexCommand cite
key "DUANE1987216"

\end_inset

, in which candidate states are generated by a dynamical method which can
 avoid the random walk aspect of the exploration.
\end_layout

\begin_layout Subsection
The hybrid Monte Carlo algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:The-hybrid-Monte"

\end_inset


\end_layout

\begin_layout Standard
The hybrid Monte Carlo algorithm was originally developed by Duane et.al.
 for application in quantum chromodynamics
\begin_inset CommandInset citation
LatexCommand cite
key "DUANE1987216"

\end_inset

.
 Radford Neal in his book on Bayesian Learning for Neural Networks
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

successfully applies this technique to Bayesian learning.
 The algorithm merges the Metropolis algorithm (reviewed in sec 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-Metropolis-algorithm"

\end_inset

) with sampling techniques based on dynamical simulation.
 It generates a sample of points drawn from some specified distribution
 which can then be used to form Monte Carlo estimates for the expectations
 of various functions with respect to this distribution.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
maybe remove.
 maybe include reference to a relevant equation where this is important
\end_layout

\end_inset

 For Bayesian learning, we often wish to sample from the posterior distribution
 given the training data, and are interested in estimating the expectations
 needed to make predictions for test cases.
\end_layout

\begin_layout Standard
The hybrid Monte Carlo algorithm is expressed in terms of sampling from
 the 
\emph on
canonical 
\emph default
(or 
\emph on
Boltzmann
\emph default
) distribution for the state of a physical system, which is defined in terms
 of an energy function.
 The algorithm can be used to sample from any distribution for a set of
 real-valued variables for which the derivatives of the probability density
 can be computed.
 For describing the formulation of this algorithm it is convenient to retain
 the physical terminology even in non-physical contexts.
 The problem can then be described in terms of an energy function for a
 fictitious physical system.
 
\end_layout

\begin_layout Standard
Accordingly, suppose we wish to sample from some distribution for a 
\begin_inset Quotes eld
\end_inset

position
\begin_inset Quotes erd
\end_inset

 variable, 
\begin_inset Formula $\mathbf{q}$
\end_inset

, which has 
\begin_inset Formula $n$
\end_inset

 real-valued components, 
\begin_inset Formula $q_{i}$
\end_inset

.
 When used for Bayesian neural networks in section (
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Using-a-full_BNN"

\end_inset

) , 
\begin_inset Formula $\mathbf{q}$
\end_inset

 will be the set of 
\begin_inset Formula $n$
\end_inset

network parameters.
 The probability density for this variable under the canonical distribution
 is defined by :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(\boldsymbol{q})\propto\exp(-E(\bold q))\label{eq:HMC_desired}
\end{equation}

\end_inset

where 
\begin_inset Formula $E(\bold q)$
\end_inset

 is the 
\begin_inset Quotes eld
\end_inset

potential energy
\begin_inset Quotes erd
\end_inset

 function.
 Any probability density which is not zero at any point can be put in this
 form, by simply defining 
\begin_inset Formula $E(\bold q)=-\log P(\bold q)-\log Z$
\end_inset

, for any convenient 
\begin_inset Formula $Z$
\end_inset

.
\end_layout

\begin_layout Standard
To allow the use of Hamiltonian dynamics, we can introduce a 
\begin_inset Quotes eld
\end_inset

momentum
\begin_inset Quotes erd
\end_inset

 variable, 
\begin_inset Formula $\bold p$
\end_inset

.
 The canonical distribution over the 
\begin_inset Quotes eld
\end_inset

phase space
\begin_inset Quotes erd
\end_inset

 of 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

together is then defined to be
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(\bold q,\boldsymbol{p})\propto\exp(-H(\bold q,\boldsymbol{p}))\label{eq:HMC_hamiltonian}
\end{equation}

\end_inset

where 
\begin_inset Formula $H(\bold q,\boldsymbol{p})=E(\bold q)+K(\bold p)$
\end_inset

 is the 
\begin_inset Quotes eld
\end_inset

Hamiltonian
\begin_inset Quotes erd
\end_inset

 function, which gives the total energy.
 
\begin_inset Formula $K(\bold p)$
\end_inset

 is the 
\begin_inset Quotes eld
\end_inset

kinetic energy
\begin_inset Quotes erd
\end_inset

 due to the momentum, for which the usual choice is :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
K(\bold p)=\sum_{i=1}^{n}\frac{p_{i}^{2}}{2m_{i}}\label{eq:kinetic energy}
\end{equation}

\end_inset

The 
\begin_inset Formula $m_{i}$
\end_inset

 are the 
\begin_inset Quotes eld
\end_inset

masses
\begin_inset Quotes erd
\end_inset

 associated with each component.
 It is possible to adjust the masses for each component to improve efficiency,
 however for the rest of the report and project we take all of them to be
 one.
 
\end_layout

\begin_layout Standard
Since in the distribution of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:HMC_hamiltonian"

\end_inset

), 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 are independent, the marginal distribution of 
\begin_inset Formula $\bold q$
\end_inset

 is the same as that of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:HMC_desired"

\end_inset

), from which we intend to sample.
 We can proceed by defining a Markov chain that converges to the canonical
 distribution for 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

.
 The values of 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 can then be simply ignored when estimating expectations of functions of
 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

.
\end_layout

\begin_layout Standard
The overall dynamics of the system with fixed total energy can be expressed
 by the following equations:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\frac{dq_{i}}{d\tau} & =+\frac{\partial H}{\partial p_{i}}=\frac{p_{i}}{q_{i}}\\
dq_{i} & =-\frac{\partial H}{\partial q_{i}}=-\frac{\partial E}{\partial q_{i}}
\end{align}

\end_inset

where 
\begin_inset Formula $\tau$
\end_inset

, is the fictitious time in which the state evolves.
 To be able to run these dynamics, we must be able to compute the partial
 derivatives of 
\begin_inset Formula $E$
\end_inset

 with respect to the the 
\begin_inset Formula $q_{i}$
\end_inset

.
 Radford Neal in his book
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

 shows that the transformation preserves volume and is reversible.
 Therefore the transformation can be used as the transition operator for
 a Markov chain and will leave 
\begin_inset Formula $P(\boldsymbol{q})$
\end_inset

 invariant.
 Evolution under the Hamiltonian dynamics will not sample ergodically from
 
\begin_inset Formula $P(\boldsymbol{q,\boldsymbol{p}})$
\end_inset

 because the value of the total energy 
\begin_inset Formula $H$
\end_inset

 is constant.
 Regions with different values of 
\begin_inset Formula $H$
\end_inset

 are never visited.
 To avoid this, HMC alternates between performing deterministic dynamical
 transitions and stochastic Gibbs sampling updates of the momentum.
 Since 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 are independent , 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 may be updated without reference to 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

.
 For the kinetic energy function of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:kinetic energy"

\end_inset

), this is easily done, each of the 
\begin_inset Formula $p_{i}$
\end_inset

 have independent Gaussian distributions which are trivial to sample from.
 These updates of 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 change the total energy 
\begin_inset Formula $H$
\end_inset

 and hence allow the entire phase space to be explored.
 
\end_layout

\begin_layout Standard
The length in fictitious time of the trajectories is an adjustable parameter.
 It is generally better to use trajectories that result in large changes
 to 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 to avoid the random walk like effects that would result from randomizing
 the momentum after every short trajectory.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe include details rather than say refer to the book
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe include figures about HMC 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Framework of Hamiltonian dynamics is exploited by casting the probabilistic
 simulation in the form of a Hamiltonian system.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In practice, Hamiltonian dynamics can not be simulated exactly, but can
 only be approximated by some discretization using finite time steps.
 This will necessarily introduce numerical errors hence we need a scheme
 that minimizes the impact of these errors.
 In the 
\emph on
leapfrog 
\emph default
discretization, a single step finds the approximations to the position and
 momentum, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p^{*}}})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
 at time 
\begin_inset Formula $\tau+\epsilon$
\end_inset

 from 
\begin_inset Formula $(\boldsymbol{q,\boldsymbol{p}})$
\end_inset

 at time 
\begin_inset Formula $\tau$
\end_inset

 as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
p_{i}(\tau+\frac{\epsilon}{2}) & \;=\; p_{i}(\tau)\;-\;\frac{\epsilon}{2}\frac{\partial E}{\partial q_{i}}(\mathbf{q}(\tau))\label{eq:leapfrog}\\
q_{i}(\tau+\epsilon) & \;=\; q_{i}(\tau)\;+\;\epsilon\frac{p_{i}(\tau+\frac{\epsilon}{2})}{mi}\\
p_{i}(\tau+\epsilon) & \;=\; p_{i}(\tau+\frac{\epsilon}{2})\;-\;\frac{\epsilon}{2}\frac{\partial E}{\partial q_{i}}(\mathbf{q}(\tau+\epsilon))\label{eq:leapfrog end}
\end{align}

\end_inset

The leapfrog step consists of a half-step for the 
\begin_inset Formula $p_{i}$
\end_inset

 , followed by a full step for 
\begin_inset Formula $q_{i}$
\end_inset

, and another half-step for the 
\begin_inset Formula $p_{i}$
\end_inset

.
 To follow the dynamics for some period of time, 
\begin_inset Formula $\Delta\tau,$
\end_inset

 a value of 
\begin_inset Formula $\epsilon$
\end_inset

 is chosen which is small enough to give an acceptable error, and equations
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:leapfrog"

\end_inset

) - (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:leapfrog end"

\end_inset

) are applied for 
\begin_inset Formula $L=\Delta\tau/\epsilon$
\end_inset

 steps in order to reach the target time.
 The momentum variable is negated at this point to ensure that if we were
 to perform a dynamical transition starting at the end stage, we will get
 back to the initial stage.
\end_layout

\begin_layout Standard
In the 
\emph on
leapfrog
\emph default
 discretization scheme, the phase space volume remains preserved despite
 the discretization.
 The dynamics are also easily reversible.
 However, the value of 
\begin_inset Formula $H$
\end_inset

 no longer remains exactly constant, this can introduce bias in the simulation.
 
\end_layout

\begin_layout Standard
HMC cancels these effects exactly by adding a Metropolis accept/reject stage
 after 
\begin_inset Formula $L$
\end_inset

 leapfrog steps.
 If the original state is 
\begin_inset Formula $(\boldsymbol{q,\boldsymbol{p}})$
\end_inset

, and we get to the new state 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p^{*}}})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
 after 
\begin_inset Formula $L$
\end_inset

 leapfrog steps, the new state is then treated as a proposal state and is
 accepted with probability:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
min(1,\frac{\exp(-H(\boldsymbol{q^{*},\boldsymbol{p^{*}}}))}{\exp(-H(\boldsymbol{q,\boldsymbol{p}}))}
\end{equation}

\end_inset

In detail , given the number of of leapfrog steps, L, a dynamical transition
 is performed as follows:
\end_layout

\begin_layout Enumerate
Start from the current state, 
\begin_inset Formula $(\boldsymbol{q,\boldsymbol{p}})=(\boldsymbol{\hat{q}}(0),\boldsymbol{\hat{p}}(0))$
\end_inset

.
 Perform 
\begin_inset Formula $L$
\end_inset

 leapfrog steps with a step-size of 
\begin_inset Formula $\epsilon$
\end_inset

, resulting in the state 
\begin_inset Formula $(\boldsymbol{\hat{q}}(\epsilon L),\boldsymbol{\hat{p}}(\epsilon L))$
\end_inset


\end_layout

\begin_layout Enumerate
Negate the momentum variables, to produce the proposal state 
\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p}^{*}})=(\boldsymbol{\hat{q}}(\epsilon L),\boldsymbol{-\hat{p}}(\epsilon L))$
\end_inset

.
\end_layout

\begin_layout Enumerate
Accept 
\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p}^{*}})$
\end_inset

 as the new state with probability:
\begin_inset Formula 
\[
min(1,\frac{\exp(-H(\boldsymbol{q^{*},\boldsymbol{p^{*}}}))}{\exp(-H(\boldsymbol{q,\boldsymbol{p}}))}
\]

\end_inset

otherwise let the new state be the same as the old.
\end_layout

\begin_layout Standard
It is important to maintain satisfactory acceptance rates by tuning the
 step-sizes 
\begin_inset Formula $\epsilon$
\end_inset

 and the number of leapfrog steps 
\begin_inset Formula $L$
\end_inset

.
 A simple adaptive version of HMC is used in this report as implemented
 in the code accompanying 
\begin_inset CommandInset citation
LatexCommand cite
key "Ranzato10factored3-way"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
ask THang
\end_layout

\end_inset

We track the average acceptance rate of the HMC move proposals, using an
 exponential moving average.
 If the average acceptance larger than a target acceptance rate, we can
 increase the step-size ,
\begin_inset Formula $\epsilon$
\end_inset

, to improve the mixing rate of the Markov chain.
 If the acceptance rate is too low, the step-size can be decreased to improve
 the acceptance rate but yielding a more conservative mixing rate.
\end_layout

\begin_layout Subsection
Intriguing properties of Neural Networks 
\end_layout

\begin_layout Standard
Some interesting properties of neural networks have been recently investigated.
 
\end_layout

\begin_layout Section
Bayesian Optimisation
\end_layout

\begin_layout Standard
Bayesian Optimisation is the model based optimisation of black box functions.
 
\end_layout

\begin_layout Subsection
High Dimensional Bayesian Optimisation 
\end_layout

\begin_layout Standard
An original goal of this project was to explore Bayesian Optimisation in
 high dimensions .
 This has not been thoroughly explored in the available literature.
 However two good papers have tried to tackle this problem.
 
\end_layout

\begin_layout Subsubsection
Rembo
\end_layout

\begin_layout Standard
Developed by Ziyu wang ..
 
\end_layout

\begin_layout Subsubsection
Add-GP-UCB
\end_layout

\begin_layout Standard
Was developed at CMU by ..
\end_layout

\begin_layout Section
Bayesian Optimisation with Bayesian Neural Networks
\begin_inset CommandInset label
LatexCommand label
name "sub:Using-a-full_BNN"

\end_inset


\end_layout

\begin_layout Subsection
Bayesian Neural Networks
\end_layout

\begin_layout Standard
Neural networks discussed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Neural-Networks"

\end_inset

, used maximum likelihood to determine the network parameters.
 Regularized maximum likelihood can be interpreted as MAP (maximum a posteriori)
 approach in which the regularizer can be viewed as the logarithm of a prior
 parameter distribution.
 However, a full Bayesian treatment of neural networks, requires us to marginali
ze over the posterior distribution of parameters
\begin_inset CommandInset citation
LatexCommand cite
key "bishop2006pattern,neal1996bayesian"

\end_inset

.
 In this section we discuss an implementation of a Bayesian neural network
 in which network parameters are updated using the hybrid Monte Carlo algorithm.
 The hyperparameters are updated separately by using Gibbs sampling.
 
\end_layout

\begin_layout Standard
Bayesian learning for neural networks is a difficult problem, due to the
 typically complex nature of the posterior distribution.
 The hybrid Monte Carlo(HMC) algorithm is particularly suitable for this
 problem, due to its avoidance of random walk behaviour as discussed in
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-hybrid-Monte"

\end_inset

.
\end_layout

\begin_layout Standard
A neural network can be parametrized by its weights and biases, collectively
 denoted as 
\begin_inset Formula $\boldsymbol{\theta},$
\end_inset

 that define what network from input to output is denoted by the network.
 This function can then be written as 
\begin_inset Formula $f(\mathbf{x},\boldsymbol{\theta})$
\end_inset

, where x is the input to the network.
 A prior can be defined on the network parameters, this prior can depend
 on some hyperparameters, 
\begin_inset Formula $\mathbf{\gamma}$
\end_inset

.
 The prior density for the parameters can be written as 
\begin_inset Formula $P(\theta\,|\,\gamma)$
\end_inset

 and the prior density for the hyperparameters can be written as 
\begin_inset Formula $P(\gamma).$
\end_inset

 We have a set of training cases collectively given by 
\begin_inset Formula $D=(x^{(1)},y^{(1)}),\dots,(x^{(n)},y^{(n)})$
\end_inset

 , consisting of independent pairs of input values, 
\begin_inset Formula $x^{(i)}$
\end_inset

, and target values, 
\begin_inset Formula $y^{(i)}$
\end_inset

.
 We aim to model the conditional distribution of target values given the
 input values.
 The required conditional probability density is given by 
\begin_inset Formula $P(y\,|\, x,\theta,\gamma).$
\end_inset


\end_layout

\begin_layout Standard
The ultimate objective is to predict the target value for new test cases,
 
\begin_inset Formula $y^{(n+1)},$
\end_inset

 given the corresponding inputs, 
\begin_inset Formula $x^{(n+1)},$
\end_inset

using the information in the training set.
 
\end_layout

\begin_layout Subsection
Using a hybrid model
\end_layout

\begin_layout Standard
A model where the last layer of hidden units are fed to the BLR to obtain
 
\end_layout

\begin_layout Subsubsection
Results 
\end_layout

\begin_layout Subsection
Using a full Bayesian neural network
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
add illustration of neural network from Neal pg17.
 Prior just show 10 random NN's .
 Then train using HMC then draw 10 randomNN's 
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
tHEANO WAS used
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Markov Chain Monte Carlo methods
\end_layout

\begin_layout Subsubsection
Results 
\end_layout

\begin_layout Subsection
Results and Discussion
\end_layout

\begin_layout Standard
Maybe like this
\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
The results are very promising 
\end_layout

\begin_layout Subsection
Potential applications/Future work
\end_layout

\begin_layout Standard
This system promises to provide better results for high-dimensional functions.
 Add Nilesh's paper to this 
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "bibliography"
options "bibtotoc,plain"

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
\start_of_appendix
Risk Assessment Retrospective
\end_layout

\begin_layout Standard
The risk assessment submitted at the start of the project identified frequent
 computer use as the main potential hazard.
 This assessment was accurate and no other hazards were encountered during
 the execution of the project.
 To avoid repetitive stress injury from excessive computer use, frequent
 breaks were taken by the author.
 Several exercises and best practices
\begin_inset CommandInset citation
LatexCommand cite
key "dugan2011healthy"

\end_inset

 were employed to reduce the risk further.
 If the project is to be carried out again, the risk assessment will remain
 the same.
\end_layout

\end_body
\end_document
