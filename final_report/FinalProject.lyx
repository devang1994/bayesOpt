#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass IIBproject
\begin_preamble
\newcommand{\argmin}{\operatornamewithlimits{argmin}}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\xvec}{\boldsymbol{x}}
\newcommand{\thevec}{\boldsymbol{\theta}}
\newcommand{\gvec}{\boldsymbol{\gamma}}
\usepackage{algorithm,algpseudocode}
\end_preamble
\use_default_options true
\begin_modules
eqs-within-sections
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2.5cm
\topmargin 2.5cm
\rightmargin 2.5cm
\bottommargin 2.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Bayesian Optimisation using Neural Networks
\end_layout

\begin_layout Author
Devang Agrawal (Queens')
\end_layout

\begin_layout Project Group
F-
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand include
filename "Abstract.lyx"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Acknowledgement
\end_layout

\begin_layout Standard
First, I would like to thank my supervisor, Professor Zoubin Ghahramani,
 for all the advice and encouragement he has provided during the course
 of this project.
 His openness to new ideas, and his ability to provide insightful criticism
 have made working with him a delightful experience.
 I would like to thank Thang Bui, Nilesh Tripuraneni and Amar Shah for providing
 intelligent ideas and helping me throughout the execution of the project.
 This project will not have been possible without their able mentorship.
 I would like to thank my Director of Studies, Dr Andrew Gee for being a
 constant source of support during my time at Cambridge.
 
\end_layout

\begin_layout Standard
I would like to thank Dr Adrian Weller and Dr David Barrett for their helpful
 discussions during the course of the project.
 I would like to thank Professor Radford Neal for laying down most of the
 foundational work on which this project is based.
 I would like to thank my family and friends for their love and support
 throughout the course of the project.
\end_layout

\begin_layout Standard
Finally, I would like to thank the Cambridge Commonwealth European and Internati
onal trust for awarding me the Manmohan Singh Undergraduate scholarship
 which has enabled me to study at Cambridge.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Traditionally machine learning algorithms have focussed on using a set of
 expertly curated features of inputs to make predictions.
 However in various tasks, especially in computer vision and natural language
 processing, the design of these features can be very complex.
 In many situations it can be difficult to know what features should be
 extracted.
 Neural networks excel at such tasks as they can discover not only the mapping
 from the representation to the output but the representation itself.
 This approach is called 
\emph on
representation learning.
 
\emph default
Learned representations often result in much better performance than can
 be obtained with hand-designed representations.
 They also allow machine learning systems to rapidly adapt to new tasks,
 with minimal human intervention.
 A representation learning algorithm can discover a good set of features
 for a complex task in hours to months.
 Manually designing features for a complex task can require a great deal
 of human time and effort; it can possibly take decades for an entire community
 of researchers.
 
\end_layout

\begin_layout Standard
Such representational learning capabilities have allowed neural networks
 to reach state of the art performance in several applications including
 computer vision and natural language processing.
 They have been used to get human-level performance in several video games
 
\begin_inset CommandInset citation
LatexCommand cite
key "mnih2015human"

\end_inset

 and have been used in systems to master the game of 
\begin_inset Quotes eld
\end_inset

Go
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "silver2016mastering"

\end_inset

.
 An 
\emph on
autoencoder
\emph default
 network is an excellent example of a representation learning algorithm
 
\begin_inset CommandInset citation
LatexCommand cite
key "hinton2006reducing"

\end_inset

.
 An autoencoder is the combination of an 
\emph on
encoder
\emph default
 function that converts the input data into a diï¬€erent representation, and
 a 
\emph on
decoder
\emph default
 function that converts the new representation back into the original format.
 Autoencoders are trained to preserve as much information as possible when
 an input is run through the encoder and then the decoder.
 By having a 
\emph on
bottleneck 
\emph default
hidden layer as illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:An-illustration-autoencoder"

\end_inset

, the algorithm can automatically learn a low dimensional code to efficiently
 represent the input data.
 
\end_layout

\begin_layout Standard
Most neural network applications use maximum likelihood estimates for the
 parameters of the neural network, such estimates can be found by minimising
 an error function such as the sum of squared errors between the target
 and predictions, for real-valued outputs.
 The backpropogation algorithm can be used to calculate the gradients of
 the error with respect to each of the parameters, this can then be used
 in a gradient based optimisation schedule such as Adam 
\begin_inset CommandInset citation
LatexCommand cite
key "kingma2014adam"

\end_inset

.
 However, for various applications, it is often desirable to estimate the
 posterior distribution of the parameters of the neural networks.
 We can use a Bayesian approach to neural network learning to find the posterior
 distribution of the network parameters by combining a simple prior on the
 network weights with the likelihoods of points observed in the training
 data 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 Such a posterior distribution can give the predictive distributions of
 the target values in new 
\begin_inset Quotes eld
\end_inset

test
\begin_inset Quotes erd
\end_inset

 cases, given the input for that case, and the inputs and targets in the
 training cases.
 Having a predictive distribution on target values is particularly useful
 for sequential decision making and active learning tasks where it is important
 to know both, the prediction and the uncertainty associated with it.
 
\end_layout

\begin_layout Standard
Bayesian optimisation is an active learning method, in which we try to optimise
 a black-box function 
\begin_inset Formula $f$
\end_inset

 which is expensive to evaluate.
 It has been successfully used in many wide ranging applications such as
 hyper-parameter tuning in expensive machine learning algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "snoek2012practical"

\end_inset

, experiment design 
\begin_inset CommandInset citation
LatexCommand cite
key "jones1998efficient"

\end_inset

, optimizing control strategies in complex systems 
\begin_inset CommandInset citation
LatexCommand cite
key "cully2015robots"

\end_inset

, and scientific simulation based studies 
\begin_inset CommandInset citation
LatexCommand cite
key "brochu2010tutorial"

\end_inset

.
 Bayesian optimization finds the optimum of 
\emph on

\begin_inset Formula $f$
\end_inset


\emph default
 by using the information from all the previous evaluations of the function
 to learn a distribution over functions.
 The algorithm then endeavours to optimise the function in as few queries
 as possible by managing exploration and exploitation 
\begin_inset CommandInset citation
LatexCommand cite
key "mockus1978application"

\end_inset

.
 An accurate and cheap model for the distribution over functions is critical
 to the effectiveness of the approach, typically Gaussian processes (GPs)
 
\begin_inset CommandInset citation
LatexCommand cite
key "rasmussen2006gaussian"

\end_inset

 are used to model this distribution over functions.
 However, GPs can only model a limited class of functions well.
 The class of functions that can be modelled by the GP depends on its covariance
 function which encodes the assumptions about the function.
 A more expressive covariance function can increase the expressivity of
 the GP, however the predictive distribution at each point is still restricted
 to be a Gaussian.
 Moreover, choosing the structural form of the covariance function is a
 very challenging task and requires significant human intervention 
\begin_inset CommandInset citation
LatexCommand cite
key "duvenaud2014automatic"

\end_inset

.
 Recently some work has been done on frameworks for automatic kernel structure
 discovery 
\begin_inset CommandInset citation
LatexCommand cite
key "duvenaud2013structure"

\end_inset

, however that framework also has limitations.
 This problem is exacerbated when using GPs on a high dimensional input
 space, which restricts the dimensionality of the functions which can be
 optimized by this method.
 Another problem with GPs is that they scale cubically with the number of
 observations, as they require the inversion of a dense covariance matrix.
 This can make it challenging to use them on functions which require a moderatel
y large number of evaluations to optimise.
 High dimensional functions and functions defined on a very large domain
 can often give rise to situations where a large number of function evaluations
 are needed for optimisation.
 
\end_layout

\begin_layout Standard
In this project we aim to use the predictive distribution described by a
 Bayesian neural network (BNN) to model the distribution over functions,
 to perform Bayesian optimisation.
 This provides a very flexible prior on the functions and can model a much
 wider class of functions.
 This method also scales linearly with the number of observations and can
 hence allow optimisation when a large number of function evaluations are
 needed.
 Neural networks can employ multiple non-linear transforms to extract relevant
 information from high dimensional inputs.
 This can allow them to learn an accurate model in a high-dimensional input
 space to effectively perform Bayesian optimisation.
 Another possible extension of this approach to performing high dimensional
 Bayesian optimisation could be to use autoencoders to learn a mapping into
 a low-dimensional space in which Bayesian optimisation can be performed
 more easily.
 
\end_layout

\begin_layout Standard
A prior is defined on the distribution of functions by defining simple priors
 on the parameters of the neural networks, this provides a very flexible
 overall prior on the distribution of functions.
 Generally Gaussian priors are used on the parameters of the network, it
 is known that in the limit of the number of hidden units going to infinity,
 the priors over the functions implied by the priors converges to a Gaussian
 process 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 It is also possible to use other other stable priors to encode prior informatio
n about the functions.
 This provides us the opportunity to model non-smooth functions and other
 functions whose behaviours not easily described by the GPs.
 For instance, Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Functions-Cauchy-prior"

\end_inset

 shows two functions drawn from priors for a network where weights and biases
 for the output have Cauchy distributions(stable distribution with 
\begin_inset Formula $\alpha=1$
\end_inset

).
 The weights and biases into the hidden units have independent Gaussian
 distributions 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/CauchyPrior.png
	lyxscale 40
	width 80col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Functions drawn from Cauchy priors on for networks with step-function hidden
 units 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 Function on the left are from a network with 150 hidden units, those on
 the right from a network with 10000 hidden units.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Functions-Cauchy-prior"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Autoencoder_structure.png
	width 80col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An illustration of an autoencoder network with a bottleneck hidden layer.
 Such a network can be used to automatically learn a low dimensional code
 for the input data 
\begin_inset CommandInset citation
LatexCommand cite
key "hinton2006reducing"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:An-illustration-autoencoder"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
The Introduction (1) describes the Bayesian optimisation method and explains
 why Bayesian neural networks are well suited for performing Bayesian optimisati
on
\end_layout

\end_inset

The report is organised into 6 sections.
 In section (2) we give a brief introduction to neural networks and how
 they can be used to create probabilistic models.
 In section (3) we review Markov chain Monte Carlo methods including the
 Metropolis algorithm and the hybrid Monte Carlo algorithm.
 Section (4) serves as a brief introduction to Bayesian optimisation, we
 also briefly review the existing literature on performing Bayesian optimisation
 in high dimensions.
 In Section (5) we review Bayesian neural networks and describe how to use
 them for Bayesian optimisation, we compare the performance of our method
 to one using Gaussian processes and report competitive results.
 The Conclusion (6) presents the main conclusions of the project and suggests
 some ideas for future work.
\end_layout

\begin_layout Section
Neural Networks
\begin_inset CommandInset label
LatexCommand label
name "sec:Neural-Networks"

\end_inset


\end_layout

\begin_layout Standard
Neural networks use multiple non-linear transforms to map from an input
 to an output.
 They are known to have excellent feature selection properties and define
 the current state of the art in object recognition and natural language
 processing tasks 
\begin_inset CommandInset citation
LatexCommand cite
key "Bengio-et-al-2015-Book"

\end_inset

.
 For this project we primarily deal with 
\begin_inset Quotes eld
\end_inset


\emph on
feedforward
\emph default

\begin_inset Quotes erd
\end_inset

 networks, these networks take in a set of real inputs, 
\begin_inset Formula $x_{i}$
\end_inset

, and then compute one or more output values, 
\begin_inset Formula $f_{k}(\boldsymbol{x})$
\end_inset

, using some number of layers of 
\emph on
hidden
\emph default
 units.
 Here, we illustrate the basic concepts of neural networks by considering
 a simple network with one hidden layer such as the one shown in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:An-illustration-NN"

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/neuralNetIllustration.png
	width 70col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An illustration of a neural network with one hidden layer.
 The input units at the bottom are fixed to their value depending on the
 data point.
 The values of the hidden units are then computed, followed by the values
 of the output units.
 The value for a hidden or output unit is a function of the weighted sum
 of values it receives from the units that are connected to it via the arrows.
 More hidden layers can be trivially added between the existing hidden units
 and the output units 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:An-illustration-NN"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 The outputs can be calculated as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
f_{k}(\boldsymbol{x}) & = & b_{k}+\sum_{j}v_{jk}h_{j}(x)\\
h_{j}(\boldsymbol{x)} & = & \tanh(a_{j}+\sum_{i}u_{ij}x_{i})
\end{eqnarray}

\end_inset

Here, 
\begin_inset Formula $u_{ij}$
\end_inset

 is the 
\emph on
weight 
\emph default
on the connection from the input unit 
\emph on

\begin_inset Formula $i$
\end_inset

 
\emph default
to the hidden unit 
\begin_inset Formula $j$
\end_inset

; similarly, 
\begin_inset Formula $v_{jk}$
\end_inset

 , is the weight on the connection from the hidden unit 
\begin_inset Formula $j$
\end_inset

 to the output unit 
\begin_inset Formula $k$
\end_inset

.
 The 
\begin_inset Formula $a_{j}$
\end_inset

 and 
\begin_inset Formula $b_{k}$
\end_inset

 are the 
\emph on
biases
\emph default
 of the hidden units and the output units respectively.
 These weights and networks collectively constitute the set of parameters
 of the network.
 
\end_layout

\begin_layout Standard
Each output value, 
\begin_inset Formula $f_{k}(\boldsymbol{x})$
\end_inset

, is a weighted sum of the last hidden unit values, plus a bias.
 Each hidden unit computes a similar weighted sum of input values, and then
 passes it though a non-linear 
\emph on
activation function.
 
\emph default
In this project we choose the hyperbolic tangent (tanh) as the activation
 function, it is an asymmetric function of sigmoidal shape as shown in Figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-Hyperbolic-Tangent"

\end_inset

.
 Its value is close to 
\begin_inset Formula $-1$
\end_inset

 for large negative numbers,
\begin_inset Formula $+1$
\end_inset

 for large positive numbers and zero for zero argument.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/relu.png
	lyxscale 30
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The Rectified Linear Activation function
\begin_inset CommandInset label
LatexCommand label
name "fig:The-Rectified-LinearU"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/tanh.png
	lyxscale 30
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The Hyperbolic Tangent Activation function
\begin_inset CommandInset label
LatexCommand label
name "fig:The-Hyperbolic-Tangent"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Here we show the rectified linear(ReLU) and the hyperbolic tangent(tanh)
 activation function.
 The ReLU function is very popular with deep feedforward networks.
 Being very close to linear they preserve many properties that make linear
 models easy to optimize with gradient based methods.
 However, they are not smooth, the abrupt changes in gradients associated
 with them can lead to issues when building probabilistic models 
\begin_inset CommandInset citation
LatexCommand cite
key "Snoek:2015aa"

\end_inset

.
 However, tanh functions are smooth over their entire domain and are hence
 suited for building probabilistic models.
\end_layout

\end_inset


\end_layout

\end_inset

 The Rectified linear unit (ReLU) function is also a very popular activation
 function, being very close to linear, they preserve many properties that
 make linear models easy to optimise with gradient based methods.
 They are particularly popular for training 
\begin_inset Quotes eld
\end_inset

deep
\begin_inset Quotes erd
\end_inset

 neural network models, where their trainability allows the network to achieve
 an excellent performance.
 However their un-smooth nature, with abrupt changes in their gradient can
 cause issues when using them to build probabilistic models.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-Rectified-LinearU"

\end_inset

 shows the ReLU activation function.
 Use of a non-linear activation function allows the overall function defined
 by the neural network to be non-linear.
 It allows the hidden units to potentially represent 
\begin_inset Quotes eld
\end_inset

hidden features
\begin_inset Quotes erd
\end_inset

 in the input that can be useful in computing the appropriate outputs.
 
\end_layout

\begin_layout Standard
It has been shown that a neural network with one hidden layer can approximate
 any function defined on a compact domain arbitrarily closely, if enough
 hidden units are used 
\begin_inset CommandInset citation
LatexCommand cite
key "Hornik1991251,cybenko1989approximation,funahashi1989approximate"

\end_inset

.
 Nevertheless, more elaborate network architectures have advantages and
 are often used.
 Multiple hidden layers can be easily stacked between the current hidden
 units and the output units.
 Such 
\begin_inset Quotes eld
\end_inset

deep
\begin_inset Quotes erd
\end_inset

 networks are commonly used for a wide variety of machine learning applications.
 However it should be noted that in feedforward networks, connections are
 not allowed to form cycles.
 This is important to allow the value of the output to be computed in a
 single forward pass, in time proportional to the number of network parameters.
 
\end_layout

\begin_layout Subsection
Training neural networks
\end_layout

\begin_layout Standard
We can define probabilistic models for regression tasks by using the network
 outputs to define the conditional distribution for the targets, 
\begin_inset Formula $\boldsymbol{y}$
\end_inset

, for various values of the input vector 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

.
 For a regression model with real-valued targets, 
\begin_inset Formula $y_{k}$
\end_inset

, the conditional distribution of the targets might be defined to be Gaussian,
 with 
\begin_inset Formula $y_{k}$
\end_inset

 having a mean 
\begin_inset Formula $f_{k}(\boldsymbol{x})$
\end_inset

 and a standard deviation of 
\begin_inset Formula $\sigma_{k}$
\end_inset

.
 We often assume the different outputs to be independent, given the input.
 This gives:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
P(\boldsymbol{y}|\boldsymbol{x}) & = & \prod_{k}\frac{1}{\sqrt{2\pi\sigma_{k}^{2}}}\exp(-\frac{(f_{k}(\boldsymbol{x})-y_{k})^{2}}{2\sigma^{2}})\label{eq:gaussian noise model}
\end{eqnarray}

\end_inset

The 
\begin_inset Quotes eld
\end_inset

noise level
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Formula $\sigma_{k}$
\end_inset

, might be fixed or treated as a hyper-parameter.
 The weights and biases of the neural network can be learnt on a set of
 
\emph on
training cases, 
\emph default

\begin_inset Formula $\mathbf{D}=\{(x^{(1)},y^{(1)}),\dots,(x^{(n)},y^{(n)})\}$
\end_inset

, giving independent examples of inputs, 
\begin_inset Formula $\boldsymbol{x}^{(i)}$
\end_inset

, and associated targets 
\begin_inset Formula $\boldsymbol{y}^{(i)}$
\end_inset

.
 Standard neural network training procedures adjust the weights and biases
 in the network so as to minimize a measure of 
\begin_inset Quotes eld
\end_inset

error
\begin_inset Quotes erd
\end_inset

 on the training cases, most commonly, the sum of the squared differences
 between the network outputs and targets.
 Minimization of this error measure is equivalent to maximum likelihood
 estimation of the Gaussian noise model of equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:gaussian noise model"

\end_inset

, since negative log likelihood with this model is proportional to the sum
 of squared errors.
 
\end_layout

\begin_layout Standard
A gradient-based approach is commonly used to find the weights and biases
 that minimize the chosen error function.
 The derivatives of the error with respect to the weights and biases can
 be calculated by using the 
\emph on
backpropagation
\emph default
 algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "Bengio-et-al-2015-Book,rumelhart1988learning"

\end_inset

.
 Typically many local minima are present, but good solutions are often found
 despite this.
 
\end_layout

\begin_layout Standard
Neural networks have a large number of parameters which makes overfitting
 a significant problem when training neural networks.
 To reduce overfitting a penalty term proportional to the sum of the squares
 of the weights and biases is often added to the error function.
 This modification is known as 
\emph on
weight decay, 
\emph default
since its effect is to bias the training procedure in favour of small weights.
 Determining the proper magnitude of weight decay is often difficult --
 too little weight decay, the network may 
\begin_inset Quotes eld
\end_inset

overfit
\begin_inset Quotes erd
\end_inset

, but too much weight decay, the network will 
\begin_inset Quotes eld
\end_inset

underfit
\begin_inset Quotes erd
\end_inset

 and ignore the data.
 Adding weight decay can be interpreted as having a Gaussian prior with
 mean zero and some standard deviation, 
\begin_inset Formula $\sigma_{w}$
\end_inset

, on the weights and biases of the neural network.
 
\end_layout

\begin_layout Standard
Cross validation is often used to find an appropriate weight penalty 
\begin_inset CommandInset citation
LatexCommand cite
key "stone1974cross"

\end_inset

.
 In its simplest form, the amount of weight decay is chosen to optimise
 performance on a validation set separate from the cases used to estimate
 the network parameters.
 
\end_layout

\begin_layout Standard
In the Bayesian approach to neural network learning, the objective is to
 find the predictive distribution for the target values in new 
\begin_inset Quotes eld
\end_inset

test
\begin_inset Quotes erd
\end_inset

 cases, given the input for that case, and the inputs and targets in the
 training cases (
\begin_inset Formula $\boldsymbol{D}$
\end_inset

).
 The predictive distribution is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
P(y^{(n+1)}|\xvec^{(n+1)},\boldsymbol{D}) & =\int P(y^{(n+1)}|\xvec^{(n+1)},\boldsymbol{\theta})P(\boldsymbol{\theta|\mathbf{D}})d\thevec
\end{align}

\end_inset

Here, 
\begin_inset Formula $\thevec$
\end_inset

 represents the network parameters (weights and biases).
 The posterior density for these parameters is proportional to the product
 of the prior on them and the likelihood function given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
L(\boldsymbol{\theta|\mathbf{D}}) & =\prod_{c=1}^{n}P(y^{(c)}|\xvec^{(c)},\boldsymbol{\theta})
\end{align}

\end_inset

The distribution of the target values, 
\begin_inset Formula $y^{(i)}$
\end_inset

, given the corresponding inputs, 
\begin_inset Formula $\boldsymbol{x}^{(i)}$
\end_inset

, and the parameters of the network is defined by the type of model with
 which the network is being used.
 For the regression model, it is given by equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:gaussian noise model"

\end_inset

.
\end_layout

\begin_layout Section
Markov Chain Monte Carlo methods
\begin_inset CommandInset label
LatexCommand label
name "sec:Markov-Chain-Monte"

\end_inset


\end_layout

\begin_layout Standard
Markov chain Monte Carlo(MCMC) methods are a class of algorithms for sampling
 from a desired probability distribution 
\begin_inset CommandInset citation
LatexCommand cite
key "andrieu2003introduction,neal1996bayesian"

\end_inset

.
 A Markov chain is constructed with the desired distribution as its equilibrium
 distribution.
 These models are widely applied to Bayesian models in statistics.
 MCMC methods make no assumptions about the about the form of the underlying
 distribution.
 In theory they can take account of multiple modes and the possibility that
 the main contribution to the integral may come from areas not in the vicinity
 of any mode.
 In practise though, they can under certain circumstances take a very long
 time to converge to the desired distribution.
 This is the main disadvantage of using MCMC methods.
 
\end_layout

\begin_layout Standard
In Bayesian learning, we often encounter situations where we need to evaluate
 the expectation of a function 
\begin_inset Formula $f(\theta)$
\end_inset

 with respect to the posterior probability density of the model parameters.
 Writing the posterior as 
\begin_inset Formula $Q(\theta)$
\end_inset

, the expectation can be expressed as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E[f]\;=\;\intop f(\theta)Q(\theta)d\theta
\end{equation}

\end_inset

Such expectations can be estimated by the 
\emph on
Monte Carlo 
\emph default
method, using a sample of values from 
\begin_inset Formula $Q$
\end_inset

: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E[f]\;\thickapprox\;\frac{1}{N}\sum_{t=1}^{N}f(\theta^{(t)})\label{eq:carloIntegration}
\end{equation}

\end_inset

where 
\begin_inset Formula $\theta^{(1)},\dots,\theta^{(N)}$
\end_inset

 are generated by a process that results in each of them having the distribution
 defined by 
\begin_inset Formula $Q$
\end_inset

.
 In simple Monte Carlo methods, the 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 are independent, however when 
\begin_inset Formula $Q$
\end_inset

 is a complicated distribution, generating such independent values is often
 infeasible.
 However it is often possible to generate a series of dependent values.
 The Monte Carlo integration formula of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:carloIntegration"

\end_inset

) still gives an unbiased estimate of 
\begin_inset Formula $E[f]$
\end_inset

 even when the 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 are dependent as long as the dependence is not too great 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 The estimate will still converge to the true value as N increases.
 Such a series of dependent values can be generated using a 
\emph on
Markov Chain
\emph default
 that has 
\begin_inset Formula $Q$
\end_inset

 as its stationary distribution.
 The chain can be defined by giving an 
\emph on
initial distribution
\emph default
 for the first state of the chain, 
\begin_inset Formula $\theta^{(1)}$
\end_inset

, and a set of 
\emph on
transition probabilities 
\emph default
for a new state, 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

, to follow the current state, 
\begin_inset Formula $\theta^{(t)}.$
\end_inset

 The probability densities for these transitions can be written as 
\begin_inset Formula $T(\theta^{(t+1)}|\theta^{(t)})$
\end_inset

.
 A 
\emph on
stationary (or invariant)
\emph default
 distribution, 
\begin_inset Formula $Q$
\end_inset

, is one that persists once it is established.
 This means that if 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 has the distribution 
\begin_inset Formula $Q$
\end_inset

, then 
\begin_inset Formula $\theta^{(t')}$
\end_inset

 will have the same distribution for all 
\begin_inset Formula $t'>t$
\end_inset

.
 This invariance condition can be written as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Q(\theta')=\int T(\theta'|\theta)Q(\theta)d\theta
\end{equation}

\end_inset

The invariance with respect to 
\begin_inset Formula $Q$
\end_inset

 is implied by the stronger 
\emph on
detailed balance
\emph default
 condition -- that for all 
\begin_inset Formula $\theta$
\end_inset

 and 
\begin_inset Formula $\theta'$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
T(\theta'|\theta)Q(\theta)=T(\theta|\theta')Q(\theta')\label{eq:deTAILed balance}
\end{equation}

\end_inset

A chain satisfying detailed balance is said to be 
\emph on
reversible.
\end_layout

\begin_layout Standard
An 
\emph on
ergodic 
\emph default
Markov chain has a unique invariant equilibrium distribution, to which it
 converges from any initial state.
 If we can find a Markov Chain that has 
\begin_inset Formula $Q$
\end_inset

 as its equilibrium distribution, then we can find find expectations with
 respect to 
\begin_inset Formula $Q$
\end_inset

 by using equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:carloIntegration"

\end_inset

) .
 In this case 
\begin_inset Formula $\theta^{(1)},\dots,\theta^{(N)}$
\end_inset

 are the states of the chain, some of the early states can be discarded
 since they are not representative of the equilibrium distribution.
 
\end_layout

\begin_layout Standard
To use MCMC methods to estimate an expectation with respect to some distribution
 
\begin_inset Formula $Q$
\end_inset

, we need to construct an ergodic Markov chain with 
\begin_inset Formula $Q$
\end_inset

 as the equilibrium distribution.
 The chain should rapidly converge to this distribution and the states visited
 once equilibrium is reached should not be highly dependent.
 To construct a Markov chain for a complex problem, we can combine the transitio
ns for simpler chains, since as long as each such transition leaves 
\begin_inset Formula $Q$
\end_inset

 invariant, the result of applying them in sequence will also leave 
\begin_inset Formula $Q$
\end_inset

 invariant.
 
\end_layout

\begin_layout Subsection
The Metropolis algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:The-Metropolis-algorithm"

\end_inset


\end_layout

\begin_layout Standard
The Metropolis algorithm was introduced by Metropolis et.al.
 in their classic paper in 1953 
\begin_inset CommandInset citation
LatexCommand cite
key "metropolis1953equation"

\end_inset

 .
 In the Markov chain defined by the Metropolis algorithm, a new state, 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

, is generated from the previous state, 
\begin_inset Formula $\theta^{(t)}$
\end_inset

, by first generating a 
\emph on
candidate state 
\emph default
using a specified 
\emph on
proposal distribution, 
\emph default
and then deciding whether or not to accept that state based on its probability
 density relative to the old state, with respect to the desired invariant
 distribution, 
\begin_inset Formula $Q.$
\end_inset

 If accepted, the candidate state, becomes the next state of the Markov
 chain; if it is instead rejected, the new state remains the same as the
 old state.
 
\end_layout

\begin_layout Standard
In detail, the transition from 
\begin_inset Formula $\theta^{(t)}$
\end_inset

 to 
\begin_inset Formula $\theta^{(t+1)}$
\end_inset

 is defined as follows:
\end_layout

\begin_layout Enumerate
Generate a candidate state, 
\begin_inset Formula $\theta^{*}$
\end_inset

, from a proposal distribution.
 The proposal distribution may depend on the current state, its density
 is given by 
\begin_inset Formula $S(\theta^{*}\,|\,\theta^{(t)})$
\end_inset

.
 It is noted that the proposal distribution must be symmetrical, satisfying
 the condition 
\begin_inset Formula $S(\theta'\,|\,\theta)=S(\theta\,|\,\theta')$
\end_inset

.
\end_layout

\begin_layout Enumerate
If 
\begin_inset Formula $Q(\theta^{*})\geq Q(\theta^{(t)})$
\end_inset

, accept the candidate state; otherwise accept the candidate state with
 probability 
\begin_inset Formula $Q(\theta')/Q(\theta)$
\end_inset

.
 For 
\begin_inset Formula $\theta'\neq\theta$
\end_inset

, the overall transition probability is then given by:
\begin_inset Formula 
\begin{equation}
T(\theta'|\theta)=S(\theta'\,|\,\theta)\min(1,Q(\theta')/Q(\theta))\label{eq:overallTransitionmetropolis}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
If the candidate state is accepted, let 
\begin_inset Formula $\theta^{(t+1)}=\theta^{*}$
\end_inset

.
 However if it was not accepted, then set 
\begin_inset Formula $\theta^{(t+1)}=\theta^{(t)}$
\end_inset

.
\end_layout

\begin_layout Standard
Following the overall transition probability in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:overallTransitionmetropolis"

\end_inset

), the detailed balance condition (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:deTAILed balance"

\end_inset

) can be verified as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
T(\theta'|\theta)Q(\theta) & =S(\theta'\,|\,\theta)\min(1,Q(\theta')/Q(\theta))Q(\theta)\\
 & =S(\theta'\,|\,\theta)\min(Q(\theta),Q(\theta'))\\
 & =S(\theta\,|\,\theta')\min(Q(\theta'),Q(\theta))\\
 & =S(\theta\,|\,\theta')\min(1,Q(\theta)/Q(\theta'))Q(\theta')\\
 & =T(\theta|\theta')Q(\theta')
\end{align*}

\end_inset

Therefore the Metropolis updates leave 
\begin_inset Formula $Q$
\end_inset

 invariant.
 
\end_layout

\begin_layout Standard
Many choices are available for the proposal distribution of the Metropolis
 algorithm.
 One simple and popular choice is a Gaussian distribution centred on 
\begin_inset Formula $\theta^{(t)},$
\end_inset

 with the variance chosen so that the probability of the candidate being
 accepted is reasonably high.
 Very low acceptance rates can be bad as they lead to successive samples
 being highly dependent.
 When sampling from a complex, high-dimensional distribution, the standard
 deviation of of the proposal distributions typically has to be very small
 compared to the extent of 
\begin_inset Formula $Q.$
\end_inset

 This is because large changes will almost certainly lead to regions of
 low probability.
 A large number of steps are hence required to move to a distant point in
 the distribution.
 The problem is made worse by the fact that these movements will take the
 form of a random walk, rather than a systematic traversal.
\end_layout

\begin_layout Standard
Simple forms of the Metropolis algorithm can be very slow when applied to
 problems such as Bayesian learning for neural networks 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

.
 As will be seen in section (
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-hybrid-Monte"

\end_inset

) , this problem can be alleviated by using the hybrid Monte Carlo algorithm
 
\begin_inset CommandInset citation
LatexCommand cite
key "DUANE1987216"

\end_inset

, in which candidate states are generated by a dynamical method which can
 avoid the random walk aspect of the exploration.
\end_layout

\begin_layout Subsection
The hybrid Monte Carlo algorithm
\begin_inset CommandInset label
LatexCommand label
name "sub:The-hybrid-Monte"

\end_inset


\end_layout

\begin_layout Standard
The hybrid Monte Carlo algorithm was originally developed by Duane et.al.
 for application in quantum chromodynamics 
\begin_inset CommandInset citation
LatexCommand cite
key "DUANE1987216"

\end_inset

.
 Radford Neal in his book on Bayesian Learning for Neural Networks 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

 successfully applies this technique to Bayesian learning for neural networks.
 The algorithm merges the Metropolis algorithm (reviewed in sec 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-Metropolis-algorithm"

\end_inset

) with sampling techniques based on dynamical simulation.
 It generates a sample of points drawn from some specified distribution
 which can then be used to form Monte Carlo estimates for the expectations
 of various functions with respect to this distribution.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
maybe remove.
 maybe include reference to a relevant equation where this is important
\end_layout

\end_inset

 For Bayesian learning, we often wish to sample from the posterior distribution
 given the training data, and are interested in estimating the expectations
 needed to make predictions for test cases.
\end_layout

\begin_layout Standard
The hybrid Monte Carlo algorithm is expressed in terms of sampling from
 the 
\emph on
canonical 
\emph default
(or 
\emph on
Boltzmann
\emph default
) distribution for the state of a physical system, which is defined in terms
 of an energy function.
 The algorithm can be used to sample from any distribution for a set of
 real-valued variables for which the derivatives of the probability density
 can be computed.
 For describing the formulation of this algorithm, it is convenient to retain
 the physical terminology even in non-physical contexts.
 The problem can then be described in terms of an energy function for a
 fictitious physical system.
 
\end_layout

\begin_layout Standard
Accordingly, suppose we wish to sample from some distribution for a 
\begin_inset Quotes eld
\end_inset

position
\begin_inset Quotes erd
\end_inset

 variable, 
\begin_inset Formula $\mathbf{q}$
\end_inset

, which has 
\begin_inset Formula $n$
\end_inset

 real-valued components, 
\begin_inset Formula $q_{i}$
\end_inset

.
 When used for Bayesian neural networks in section (
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Using-a-full_BNN"

\end_inset

) , 
\begin_inset Formula $\mathbf{q}$
\end_inset

 will be the set of 
\begin_inset Formula $n$
\end_inset

 network parameters.
 The probability density for this variable under the canonical distribution
 is defined by :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(\boldsymbol{q})\propto\exp(-E(\bold q))\label{eq:HMC_desired}
\end{equation}

\end_inset

where 
\begin_inset Formula $E(\bold q)$
\end_inset

 is the 
\begin_inset Quotes eld
\end_inset

potential energy
\begin_inset Quotes erd
\end_inset

 function.
 Any probability density which is not zero at any point can be put in this
 form, by simply defining 
\begin_inset Formula $E(\bold q)=-\log P(\bold q)-\log Z$
\end_inset

, for any convenient 
\begin_inset Formula $Z$
\end_inset

.
\end_layout

\begin_layout Standard
To allow the use of Hamiltonian dynamics, we can introduce a 
\begin_inset Quotes eld
\end_inset

momentum
\begin_inset Quotes erd
\end_inset

 variable, 
\begin_inset Formula $\bold p$
\end_inset

.
 The canonical distribution over the 
\begin_inset Quotes eld
\end_inset

phase space
\begin_inset Quotes erd
\end_inset

 of 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 together is then defined to be
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(\bold q,\boldsymbol{p})\propto\exp(-H(\bold q,\boldsymbol{p}))\label{eq:HMC_hamiltonian}
\end{equation}

\end_inset

where 
\begin_inset Formula $H(\bold q,\boldsymbol{p})=E(\bold q)+K(\bold p)$
\end_inset

 is the 
\begin_inset Quotes eld
\end_inset

Hamiltonian
\begin_inset Quotes erd
\end_inset

 function, which gives the total energy.
 
\begin_inset Formula $K(\bold p)$
\end_inset

 is the 
\begin_inset Quotes eld
\end_inset

kinetic energy
\begin_inset Quotes erd
\end_inset

 due to the momentum, for which the usual choice is :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
K(\bold p)=\sum_{i=1}^{n}\frac{p_{i}^{2}}{2m_{i}}\label{eq:kinetic energy}
\end{equation}

\end_inset

The 
\begin_inset Formula $m_{i}$
\end_inset

 are the 
\begin_inset Quotes eld
\end_inset

masses
\begin_inset Quotes erd
\end_inset

 associated with each component.
 It is possible to adjust the masses for each component to improve efficiency,
 however for the rest of the report and project, we take all of them to
 be one.
 
\end_layout

\begin_layout Standard
Since in the distribution of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:HMC_hamiltonian"

\end_inset

), 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 are independent, the marginal distribution of 
\begin_inset Formula $\bold q$
\end_inset

 is the same as that of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:HMC_desired"

\end_inset

), from which we intend to sample.
 We can proceed by defining a Markov chain that converges to the canonical
 distribution for 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

.
 The values of 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 can then be simply ignored when estimating expectations of functions of
 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

.
\end_layout

\begin_layout Standard
The overall dynamics of the system with fixed total energy can be expressed
 by the following equations:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\frac{dq_{i}}{d\tau} & =+\frac{\partial H}{\partial p_{i}}=\frac{p_{i}}{q_{i}}\\
\frac{dp_{i}}{d\tau} & =-\frac{\partial H}{\partial q_{i}}=-\frac{\partial E}{\partial q_{i}}
\end{align}

\end_inset

where 
\begin_inset Formula $\tau$
\end_inset

, is the fictitious time in which the state evolves.
 To be able to run these dynamics, we must be able to compute the partial
 derivatives of 
\begin_inset Formula $E$
\end_inset

 with respect to the the 
\begin_inset Formula $q_{i}$
\end_inset

.
 Radford Neal in his book 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

 shows that the transformation preserves volume and is reversible.
 Therefore the transformation can be used as the transition operator for
 a Markov chain and will leave 
\begin_inset Formula $P(\boldsymbol{q})$
\end_inset

 invariant.
 Evolution under Hamiltonian dynamics will not sample ergodically from 
\begin_inset Formula $P(\boldsymbol{q,\boldsymbol{p}})$
\end_inset

 because the value of the total energy 
\begin_inset Formula $H$
\end_inset

 is constant.
 Regions with different values of 
\begin_inset Formula $H$
\end_inset

 are never visited.
 To avoid this, HMC alternates between performing deterministic dynamical
 transitions and stochastic Gibbs sampling updates of the momentum.
 Since 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 are independent, 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 may be updated without reference to 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

.
 For the kinetic energy function of equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:kinetic energy"

\end_inset

), this is easily done, each of the 
\begin_inset Formula $p_{i}$
\end_inset

 have independent Gaussian distributions which are trivial to sample from.
 These updates of 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

 change the total energy 
\begin_inset Formula $H$
\end_inset

 and hence allow the entire phase space to be explored.
 
\end_layout

\begin_layout Standard
The length in fictitious time of the trajectories is an adjustable parameter.
 It is generally better to use trajectories that result in large changes
 to 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 to avoid the random walk like effects that would result from randomising
 the momentum after every short trajectory.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe include details rather than say refer to the book
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe include figures about HMC 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Framework of Hamiltonian dynamics is exploited by casting the probabilistic
 simulation in the form of a Hamiltonian system.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In practice, Hamiltonian dynamics can not be simulated exactly, but can
 only be approximated by some discretization using finite time steps.
 This will necessarily introduce numerical errors hence we need a scheme
 that minimizes the impact of these errors.
 In the 
\emph on
leapfrog 
\emph default
discretization, a single step finds the approximations to the position and
 momentum, 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p^{*}}})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
 at time 
\begin_inset Formula $\tau+\epsilon$
\end_inset

 from 
\begin_inset Formula $(\boldsymbol{q,\boldsymbol{p}})$
\end_inset

 at time 
\begin_inset Formula $\tau$
\end_inset

 as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
p_{i}(\tau+\frac{\epsilon}{2}) & \;=\;p_{i}(\tau)\;-\;\frac{\epsilon}{2}\frac{\partial E}{\partial q_{i}}(\mathbf{q}(\tau))\label{eq:leapfrog}\\
q_{i}(\tau+\epsilon) & \;=\;q_{i}(\tau)\;+\;\epsilon\frac{p_{i}(\tau+\frac{\epsilon}{2})}{mi}\\
p_{i}(\tau+\epsilon) & \;=\;p_{i}(\tau+\frac{\epsilon}{2})\;-\;\frac{\epsilon}{2}\frac{\partial E}{\partial q_{i}}(\mathbf{q}(\tau+\epsilon))\label{eq:leapfrog end}
\end{align}

\end_inset

The leapfrog step consists of a half-step for the 
\begin_inset Formula $p_{i}$
\end_inset

 , followed by a full step for 
\begin_inset Formula $q_{i}$
\end_inset

, and another half-step for the 
\begin_inset Formula $p_{i}$
\end_inset

.
 To follow the dynamics for some period of time, 
\begin_inset Formula $\Delta\tau,$
\end_inset

 a value of 
\begin_inset Formula $\epsilon$
\end_inset

 is chosen which is small enough to give an acceptable error, and equations
 (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:leapfrog"

\end_inset

) - (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:leapfrog end"

\end_inset

) are applied for 
\begin_inset Formula $L=\Delta\tau/\epsilon$
\end_inset

 steps in order to reach the target time.
 The momentum variable is negated at this point to ensure that if we were
 to perform a dynamical transition starting at the end stage, we will get
 back to the initial stage.
 This is a requirement to satisfy the detailed balance equation (eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:deTAILed balance"

\end_inset

).
 However in the current implementation this negation is practically unnecessary,
 as it will be replaced in a Gibbs sampling step before the next dynamical
 transition.
 However it can be important for other extensions of Bayesian neural networks
 such as those using hybrid Monte Carlo with persistent momentum 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian,mackay1998introduction"

\end_inset

.
\end_layout

\begin_layout Standard
In the 
\emph on
leapfrog
\emph default
 discretization scheme, the phase space volume remains preserved despite
 the discretization.
 The dynamics are also easily reversible.
 However, the value of 
\begin_inset Formula $H$
\end_inset

 no longer remains exactly constant, this can introduce bias in the simulation.
 
\end_layout

\begin_layout Standard
HMC cancels these effects exactly by adding a Metropolis accept/reject stage
 after 
\begin_inset Formula $L$
\end_inset

 leapfrog steps.
 If the original state is 
\begin_inset Formula $(\boldsymbol{q,\boldsymbol{p}})$
\end_inset

, and we get to the new state 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\lang english

\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p^{*}}})$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
\lang british
 after 
\begin_inset Formula $L$
\end_inset

 leapfrog steps, the new state is then treated as a proposal state and is
 accepted with probability:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\min(1,\frac{\exp(-H(\boldsymbol{q^{*},\boldsymbol{p^{*}}}))}{\exp(-H(\boldsymbol{q,\boldsymbol{p}}))}
\end{equation}

\end_inset

In detail, given the number of of leapfrog steps, L, and a step-size 
\begin_inset Formula $\epsilon$
\end_inset

, a dynamical transition is performed as follows:
\end_layout

\begin_layout Enumerate
Start from the current state, 
\begin_inset Formula $(\boldsymbol{q,\boldsymbol{p}})=(\boldsymbol{\hat{q}}(0),\boldsymbol{\hat{p}}(0))$
\end_inset

.
 Perform 
\begin_inset Formula $L$
\end_inset

 leapfrog steps with a step-size of 
\begin_inset Formula $\epsilon$
\end_inset

, resulting in the state 
\begin_inset Formula $(\boldsymbol{\hat{q}}(\epsilon L),\boldsymbol{\hat{p}}(\epsilon L))$
\end_inset


\end_layout

\begin_layout Enumerate
Negate the momentum variables, to produce the proposal state 
\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p}^{*}})=(\boldsymbol{\hat{q}}(\epsilon L),\boldsymbol{-\hat{p}}(\epsilon L))$
\end_inset

.
\end_layout

\begin_layout Enumerate
Accept 
\begin_inset Formula $(\boldsymbol{q^{*},\boldsymbol{p}^{*}})$
\end_inset

 as the new state with probability:
\begin_inset Formula 
\[
\min(1,\frac{\exp(-H(\boldsymbol{q^{*},\boldsymbol{p^{*}}}))}{\exp(-H(\boldsymbol{q,\boldsymbol{p}}))}
\]

\end_inset

otherwise let the new state be the same as the old.
\end_layout

\begin_layout Standard
It is important to maintain satisfactory acceptance rates by tuning the
 step-sizes 
\begin_inset Formula $\epsilon$
\end_inset

 and the number of leapfrog steps 
\begin_inset Formula $L$
\end_inset

.
 A simple adaptive version of HMC is used in this report as implemented
 in the code accompanying 
\begin_inset CommandInset citation
LatexCommand cite
key "Ranzato10factored3-way"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
ask THang
\end_layout

\end_inset

We track the average acceptance rate of the HMC move proposals, using an
 exponential moving average.
 If the average acceptance rate is larger than a target acceptance rate,
 we can increase the step-size, 
\begin_inset Formula $\epsilon$
\end_inset

, to improve the mixing rate of the Markov chain.
 If the acceptance rate is too low, the step-size can be decreased to improve
 the acceptance rate but yielding a more conservative mixing rate.
 
\end_layout

\begin_layout Section
Bayesian Optimisation
\begin_inset CommandInset label
LatexCommand label
name "sec:Bayesian-Optimisation"

\end_inset


\end_layout

\begin_layout Standard
Bayesian optimisation is a natural framework for model-based global optimisation
 of noisy expensive black-box functions.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Bayesian optimisation is the model based optimisation of black box functions.
 In this section we will primarily describe Bayesian optimisation with a
 Gaussian Process prior over the functions.
 We then briefly describe Bayesian Optimisation using a Bayesian neural
 network based prior.
\end_layout

\begin_layout Plain Layout
An enormous body of scientific literature has been devoted to the problem
 of optimizing a nonlinear function 
\begin_inset Formula $f(\boldsymbol{x})$
\end_inset

 over a compact set 
\begin_inset Formula $A$
\end_inset

.
 The problem can be formulated concisely as follows:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{equation}
\min_{x\in A\subset\mathbb{R^{d}}}f(\boldsymbol{x})\label{eq:minimisation}
\end{equation}

\end_inset


\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Bayesian optimisation is typically used for global optimisation of functions
 with expensive evaluations.
 
\end_layout

\end_inset

It relies on querying a distribution over functions defined by a relatively
 cheap surrogate model.
 An accurate model for the distribution over functions is critical to the
 effectiveness of the approach, and is typically fit using Gaussian processes(GP
s).
 In this work, we will also explore the use of neural-networks as an alternative
 to GPs to model the distribution over functions.
 
\end_layout

\begin_layout Standard
In this work, we will restrict to using Bayesian optimisation to solve global
 minimisation problems of the form :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\boldsymbol{x^{*}}=\argmin_{x\in\chi}f(\boldsymbol{x})
\]

\end_inset

where we take 
\begin_inset Formula $\chi$
\end_inset

 to be a compact subset of 
\begin_inset Formula $\mathbb{R}^{D}$
\end_inset

.
 Maximisation problems can be trivially converted to minimisation problems
 by negating the objective function.
\end_layout

\begin_layout Standard
Bayesian optimisation constructs a probabilistic model for 
\begin_inset Formula $f(\boldsymbol{x})$
\end_inset

, and then exploits this model to make decisions about where in 
\begin_inset Formula $\chi$
\end_inset

 to next evaluate the function.
 The essential philosophy is to use all the information available from previous
 evaluations of 
\begin_inset Formula $f(\boldsymbol{x})$
\end_inset

 and not simply rely on the local gradient and Hessian approximations.
 This results in a procedure that can optimize difficult non-convex functions
 with relatively few evaluations, at the cost of performing more computation
 to determine the next point to try.
 The Bayesian optimisation procedure is shown in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Bayesian-Optimisation"

\end_inset

.
\lang french

\begin_inset Float algorithm
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1] 
\backslash
For{t=1,2,...}
\end_layout

\begin_layout Plain Layout


\backslash
State{Find $x_{t}$ by optimising the acquisition function $a$ : $
\backslash
boldsymbol{x}_{t}=
\backslash
argmin_{x}a(
\backslash
boldsymbol{x})$} 
\backslash
State{Augment the dataset $
\backslash
boldsymbol{D}_{t}=
\backslash
{
\backslash
boldsymbol{D}_{t-1},((
\backslash
boldsymbol{x}{}_{t},f(
\backslash
boldsymbol{x}{}_{t})
\backslash
}$} 
\backslash
EndFor 
\backslash
end{algorithmic}
\end_layout

\end_inset


\lang french

\begin_inset Caption Standard

\begin_layout Plain Layout
Bayesian Optimisation
\begin_inset CommandInset label
LatexCommand label
name "alg:Bayesian-Optimisation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\lang british
 
\end_layout

\begin_layout Standard
When function evaluations are expensive to perform, then it is easy to justify
 some extra computation to smartly determine what evaluations to make.
 Such situations occur frequently in tasks such as hyper-parameter tuning
 in expensive machine learning algorithms, optimising control strategies
 in complex systems, scientific simulation studies etc.
 For instance, when optimising control strategies for a robotics system
 such as in 
\begin_inset CommandInset citation
LatexCommand cite
key "cully2015robots"

\end_inset

, each function evaluation can involve an experiment on a physical robot
 which can require significant human intervention and time.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
reread
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\emph on
Acquisition functions 
\emph default
are very important in Bayesian optimisation, they allow us to construct
 a utility function from the model posterior.
 They can encapsulate the trade-off between exploration and exploitation.
 To determine the next point to evaluate, we need to find the relevant global
 optima (minima or maxima depending on nature of problem and acquisition
 function) of the acquisition function, this is generally much easier than
 optimising the original function, as the acquisition function is typically
 relatively cheap to evaluate and it is also generally possible to use its
 derivatives for gradient based optimisation.
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:An-example-bayesOpt"

\end_inset

 shows the Bayesian optimisation algorithm on a toy 1D maximisation problem.
 The algorithm successfully balances exploration and exploitation based
 on the model to find the maximum in very few function evaluations.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/BayesOptToy.png
	lyxscale 50
	width 80col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
An example of using Bayesian Optimisation on a toy 1D maximization problem
 
\begin_inset CommandInset citation
LatexCommand cite
key "brochu2010tutorial"

\end_inset

.
 The figures show a Gaussian process(GP) approximation of the objective
 function over four iterations of sampled values of the objective function.
 The figure also shows the acquisition function in the lower shaded plots.
 Since its a maximisation problem, the acquisition function is high where
 the GP predicts a high objective (exploitation) and where the prediction
 uncertainty is high(exploration).
 We successively evaluate the function at the maximum values of the acquisition
 function to get close to the true maximum at 
\begin_inset Formula $t=4$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:An-example-bayesOpt"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Acquisition Functions for Bayesian Optimisation
\end_layout

\begin_layout Standard
We assume a prior on the function 
\begin_inset Formula $f(\boldsymbol{x})$
\end_inset

.
 We assume that our observations are of the form 
\begin_inset Formula $\boldsymbol{D}=\{\boldsymbol{x}_{n},y_{n}\}_{n=1}^{N}$
\end_inset

, where 
\begin_inset Formula $y_{n}\sim\mathcal{N}(f(x_{n}),\nu)$
\end_inset

and 
\begin_inset Formula $\nu$
\end_inset

 is the variance of the noise introduced into the function observations.
 The prior and the observations induce a posterior over the functions.
 The acquisition function denoted by 
\begin_inset Formula $a\,:\,\chi\rightarrow\mathbb{{R}}^{+},$
\end_inset

 determines what point in 
\begin_inset Formula $\chi$
\end_inset

 to evaluate next via a proxy optimization 
\begin_inset Formula $\boldsymbol{x}_{next}=\argmin_{x}a(\boldsymbol{x})$
\end_inset

.
 Several different acquisition functions have been proposed 
\begin_inset CommandInset citation
LatexCommand cite
key "hoffman2011portfolio,brochu2010tutorial"

\end_inset

, for this project we use the GP upper confidence bound.
 
\end_layout

\begin_layout Standard

\series bold
GP Upper Confidence Bound(GP-UCB) 
\series default
It exploits the idea of exploiting lower confidence bounds (upper, when
 considering maximisation) to construct acquisition functions that minimize
 regret over the course of their optimization 
\begin_inset CommandInset citation
LatexCommand cite
key "srinivas2009gaussian"

\end_inset

.
 These acquisition functions have the form
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
a_{LCB}(x,\boldsymbol{D},\theta)=\mu(\boldsymbol{x};\,\boldsymbol{D},\theta)-\kappa\sigma(\boldsymbol{x};\,\boldsymbol{D},\theta)
\]

\end_inset

where 
\begin_inset Formula $\theta$
\end_inset

 represents the hyperparameters of the surrogate model being used (GP or
 Bayesian neural network) , and 
\begin_inset Formula $\kappa$
\end_inset

 is a tunable parameter to balance exploitation against exploration.
 
\end_layout

\begin_layout Standard
This form of an acquisition function is very well suited for the project
 since it provides a very convenient way to explicitly balance exploration
 and exploitation via the tunable parameter, 
\begin_inset Formula $\kappa$
\end_inset

 .
 It is also very easy to evaluate for Bayesian neural networks using samples
 from the posterior of the neural network using an MCMC based approach.
 
\end_layout

\begin_layout Subsection
High Dimensional Bayesian Optimisation 
\end_layout

\begin_layout Standard
Bayesian optimisation with neural networks can also potentially deal with
 high dimensional global optimisation problems.
 Through multiple non-linear transforms neural networks can potentially
 find a non-linear lower dimensional manifold in a high dimensional space
 which encapsulates most of the variance of the objective function.
 A neural network based model may be able to take advantage of such structure
 for Bayesian optimisation.
 Running Bayesian optimisation on a high-dimensional problem is however
 very computationally expensive, requiring highly optimized and parallelized
 software.
 The efficacy of a Bayesian optimisation framework utilizing neural networks
 on a high dimensional problem, will be addressed in future work.
\end_layout

\begin_layout Standard
Here, we briefly review the currently known methods for performing Bayesian
 optimisation on high dimensional problems,
\end_layout

\begin_layout Subsubsection
High dimensional Bayesian Optimisation via Random Embeddings
\end_layout

\begin_layout Standard
Random Embeddings Bayesian Optimisation (REMBO) has been developed by Ziyu
 Wang et.al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "wang2013bayesian"

\end_inset

 for performing Bayesian optimisation on functions with low effective dimensiona
lity.
 
\end_layout

\begin_layout Standard
The effective dimensionality of a function (
\begin_inset Formula $d_{e}$
\end_inset

) can be defined as :
\end_layout

\begin_layout Standard

\series bold
Definition 1
\series default
: A function 
\begin_inset Formula $f\,:\,\mathbb{R}^{D}\rightarrow\mathbb{R}$
\end_inset

 is said to have 
\series bold
\emph on
effective dimensionality
\series default
\emph default
 
\begin_inset Formula $d_{e}$
\end_inset

 , with 
\begin_inset Formula $d_{e}<D$
\end_inset

, if there exists a linear sub-space 
\begin_inset Formula $\mathcal{T}$
\end_inset

 of dimension 
\begin_inset Formula $d_{e}$
\end_inset

 such that for all 
\begin_inset Formula $x_{T}\in\mathcal{T}\subset\mathbb{R}^{D}\text{ and }\boldsymbol{x}_{\perp}\in\mathcal{T}^{\perp}\subset\mathbb{R}^{D}$
\end_inset

 , we have 
\begin_inset Formula $f(x)=f(x_{T}+x_{\perp})=f(x_{T})$
\end_inset

, where 
\begin_inset Formula $\mathcal{T}^{\perp}$
\end_inset

 denotes the orthogonal complement of 
\begin_inset Formula $\mathcal{T}$
\end_inset

.
 
\begin_inset Formula $\mathcal{T}$
\end_inset

 is the 
\series bold
effective subspace 
\series default
of 
\begin_inset Formula $f$
\end_inset

 and 
\begin_inset Formula $\mathcal{T}^{\perp}$
\end_inset

 the 
\series bold
constant subspace.
\end_layout

\begin_layout Standard
This definition simply states that the function does not change along the
 coordinates 
\begin_inset Formula $x_{\perp}$
\end_inset

 , and which is why 
\begin_inset Formula $\mathcal{T}^{\perp}$
\end_inset

 is referred to as the constant subspace.
 
\end_layout

\begin_layout Standard
For this algorithm, it is assumed that high dimensional functions have a
 small effective dimensionality and hence the function remains almost constant
 while moving along most dimensions.
 
\end_layout

\begin_layout Standard
This method performs Bayesian optimisation in a random low dimensional embedding
 in the original high dimensional space.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:REMBO"

\end_inset

 illustrates this method by using a 
\begin_inset Formula $D=2$
\end_inset

 dimensional function where only 
\begin_inset Formula $d_{e}=1$
\end_inset

 dimension is important.
 Optimisation is performed in the embedding 
\begin_inset Formula $x1=x2$
\end_inset

, since it is guaranteed to include the optimum.
 Importantly, it should be noted, that the method is not restricted to cases
 with axis aligned intrinsic dimensions.
 
\end_layout

\begin_layout Standard
However this method is restricted to functions for which the low effective
 dimensionality assumption holds, the performance is limited in functions
 which do not have low effective dimensionality.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/Untitled 2.png
	lyxscale 20
	width 80col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
This function in 
\begin_inset Formula $D=2$
\end_inset

 dimensions only has 
\begin_inset Formula $d_{e}=1$
\end_inset

 effective dimension: the vertical axis indicated with the word important
 on the right hand side figure.
 Hence, the 1-dimensional embedding includes the 2-dimensional functionâ€™s
 optimizer.
 It is more efficient to search for the optimum along the 1-dimensional
 random embedding than in the original 2-dimensional space 
\begin_inset CommandInset citation
LatexCommand cite
key "wang2013bayesian"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:REMBO"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
High Dimensional Bayesian Optimisation via Additive Models
\end_layout

\begin_layout Standard
This method was developed by Kandasamy et.al.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kandasamy:2015aa"

\end_inset

, it makes the assumption that the objective function 
\begin_inset Formula $f$
\end_inset

 decomposes into the following additive form :
\end_layout

\begin_layout Standard

\lang english
\begin_inset Formula 
\begin{equation}
f(x)=f^{(1)}(x^{(1)})+f^{(2)}(x^{(2)})+\dots+f^{(M)}(x^{(M)})\label{eq:additive}
\end{equation}

\end_inset


\lang british
Here each 
\begin_inset Formula $x^{(j)}\in\mathcal{X}^{(j)}=[0,1]^{d_{j}}$
\end_inset

 are lower dimensional components.
 Each 
\begin_inset Formula $\mathcal{X}^{(j)}$
\end_inset

 is referred to as a group and the grouping of different dimensions into
 these groups 
\begin_inset Formula $\{\mathcal{X}^{j}\}_{j=1}^{M}$
\end_inset

as the 
\begin_inset Quotes eld
\end_inset

decomposition
\begin_inset Quotes erd
\end_inset

.
 It is important to note that the groups are disjoint.
 
\end_layout

\begin_layout Standard
This method shows excellent performance when the function is indeed additive
 with mutually exclusive lower dimensional components but the performance
 degrades when the function is not well described by these assumptions.
\end_layout

\begin_layout Section
Bayesian Optimisation with Bayesian Neural Networks
\begin_inset CommandInset label
LatexCommand label
name "sub:Using-a-full_BNN"

\end_inset


\end_layout

\begin_layout Standard
In this section, we begin by reviewing Bayesian neural networks, we build
 on the Markov chain Monte Carlo approach introduced in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Markov-Chain-Monte"

\end_inset

.
 We show some samples from the posterior of the network on a 
\begin_inset Quotes eld
\end_inset

toy
\begin_inset Quotes erd
\end_inset

 function and proceed to show the posterior mean and credible interval averaged
 over a large number of samples.
 Then we show intermediate results from optimising the one dimensional Forrester
 function 
\begin_inset CommandInset citation
LatexCommand cite
key "forrester2008engineering"

\end_inset

.
 We finally compare the performance of the algorithm with a GP based model
 on a set of popular benchmarks.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
review
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Bayesian Neural Networks
\end_layout

\begin_layout Standard
Neural networks discussed in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Neural-Networks"

\end_inset

, used maximum likelihood to determine the network parameters.
 Regularized maximum likelihood can be interpreted as maximum a posteriori(MAP)
 approach in which the regularizer can be viewed as the logarithm of a prior
 parameter distribution.
 However, a full Bayesian treatment of neural networks, requires us to marginali
ze over the posterior distribution of parameters 
\begin_inset CommandInset citation
LatexCommand cite
key "bishop2006pattern,neal1996bayesian"

\end_inset

.
 In this section we discuss an implementation of a Bayesian neural network
 in which network parameters are updated using the hybrid Monte Carlo algorithm.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
The hyperparameters are updated separately by using Gibbs sampling.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Bayesian learning for neural networks is a difficult problem, due to the
 typically complex nature of the posterior distribution.
 The hybrid Monte Carlo(HMC) algorithm is particularly suitable for this
 problem, due to its avoidance of random walk behaviour as discussed in
 section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-hybrid-Monte"

\end_inset

.
\end_layout

\begin_layout Standard
A neural network can be parametrized by its weights and biases, collectively
 denoted as 
\begin_inset Formula $\boldsymbol{\theta},$
\end_inset

 that define what function from the input to the output is represented by
 the network.
 This function can then be written as 
\begin_inset Formula $f(\mathbf{x},\boldsymbol{\theta})$
\end_inset

, where 
\begin_inset Formula $\boldsymbol{x}$
\end_inset

 is the input to the network.
 A prior can be defined on the network parameters, this prior can depend
 on some hyperparameters, 
\begin_inset Formula $\boldsymbol{\gamma}$
\end_inset

.
 The prior density for the parameters can be written as 
\begin_inset Formula $P(\boldsymbol{\theta}\,|\,\boldsymbol{\gamma})$
\end_inset

 and the prior density for the hyperparameters can be written as 
\begin_inset Formula $P(\gvec).$
\end_inset

 We have a training data-set given by 
\begin_inset Formula $\mathbf{D}=\{(\xvec^{(1)},y^{(1)}),\dots,(\xvec^{(n)},y^{(n)})\}$
\end_inset

 , consisting of independent pairs of input values, 
\begin_inset Formula $\xvec^{(i)}$
\end_inset

, and target values, 
\begin_inset Formula $y^{(i)}$
\end_inset

.
 We aim to model the conditional distribution of target values given the
 input values.
 The required conditional probability density is given by 
\begin_inset Formula $P(y\,|\,\xvec,\thevec,\gvec).$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
add illustration of neural network from Neal pg17.
 Prior just show 10 random NN's .
 Then train using HMC then draw 10 randomNN's 
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
tHEANO WAS used
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The ultimate objective is to predict the target value for new test cases,
 
\begin_inset Formula $y^{(n+1)},$
\end_inset

 given the corresponding inputs, 
\begin_inset Formula $\xvec^{(n+1)},$
\end_inset

 using the information in the training set.
 To make the prediction we require the posterior distribution for 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{\gamma}$
\end_inset

, this is proportional to the product of the prior and the likelihood due
 to the training cases:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(\boldsymbol{\theta,\boldsymbol{\gamma}\,|\,\mathbf{D}})\ \propto\ P(\gvec)P(\thevec|\gvec)\prod_{i=1}^{n}P(y^{(i)}\,|\,\xvec^{(i)},\boldsymbol{\theta},\boldsymbol{\gamma})\label{eq:probability NN}
\end{equation}

\end_inset

Predictions on new data-points can then be made by integration with respect
 to this posterior distribution.
 The prediction on new data-points is then given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(y^{(n+1)}|\xvec^{(n+1)},\boldsymbol{D})\;=\;\int P(y^{(n+1)}|\xvec^{(n+1)},\boldsymbol{\theta},\boldsymbol{\gamma})P(\boldsymbol{\theta,\boldsymbol{\gamma}\,|\,\mathbf{D}})\,d\mathbf{\thevec}\,d\mathbf{\gvec}
\end{equation}

\end_inset

For a regression model, the prediction that minimizes the expected squared-error
 loss is the mean of the predictive distribution.
 It is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{y}^{(n+1)}\;=\;\int f(x^{(n+1)},\boldsymbol{\theta})P(\boldsymbol{\theta,\boldsymbol{\gamma}\,|\,\mathbf{D}})\,d\mathbf{\thevec}\,d\boldsymbol{\gamma}\label{eq:prediction}
\end{equation}

\end_inset

Since these integrals take the form of expectation of functions with respect
 to the posterior distribution, they can be tackled by using a Markov chain
 Monte Carlo approach as reviewed in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Markov-Chain-Monte"

\end_inset

.
 We can approximate the integral with the average value of the function
 over a sample of values from the posterior.
 
\end_layout

\begin_layout Standard
The hybrid Monte Carlo method discussed in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:The-hybrid-Monte"

\end_inset

 is used to generate samples from the posterior.
 To apply this method, we first need to formulate the desired distribution
 in terms of a potential energy function.
 Since the objective is to sample from the posterior distribution for network
 parameters, the energy function will be a function of these parameters.
 The parameters 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

, will play the role of the the 
\begin_inset Quotes eld
\end_inset

position
\begin_inset Quotes erd
\end_inset

 variable, 
\begin_inset Formula $\boldsymbol{q},$
\end_inset

 of an imaginary physical system.
 The hyperparameters remain fixed throughout the hybrid Monte Carlo updates,
 hence we can ignore all energy terms depending only on the hyperparameters.
 For the generic case described by equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:probability NN"

\end_inset

) , the potential energy can be calculated by taking the negative log of
 the prior and the likelihood due to the training cases, as follows:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E(\boldsymbol{\theta})=F(\gvec)-\log P(\thevec|\gvec)-\sum_{c=1}^{n}P(y^{(c)}\,|\,\xvec^{(c)},\boldsymbol{\theta},\boldsymbol{\gamma})
\end{equation}

\end_inset

where 
\begin_inset Formula $F(\boldsymbol{\gamma})$
\end_inset

 is any convenient function of the hyperparameters.
 The detailed form of the energy function will obviously depend on the network
 architecture, the prior, and the data model used.
 Here, we put a Gaussian prior with mean zero and standard deviation 
\begin_inset Formula $\sigma_{p}$
\end_inset

 on each of the network parameters.
 As mentioned in 
\begin_inset CommandInset citation
LatexCommand cite
key "neal1996bayesian"

\end_inset

, this is not necessary for defining Bayesian neural networks, and we can
 assume different priors (such as the Cauchy distribution) to model functions
 with different properties (such as non-smooth functions).
 Also, it is possible to assume a different prior on parameters corresponding
 to different layers.
 This can provide extra flexibility in expressing our prior beliefs about
 the distribution of various parameters of the neural network.
\end_layout

\begin_layout Standard
We also assume that the targets are a single real value which can be modelled
 with a Gaussian noise distribution with standard deviation 
\begin_inset Formula $\sigma_{n}$
\end_inset

.
 The hyperparameters are then 
\begin_inset Formula $\boldsymbol{\gamma}=\{\tau_{p}\,,\,\tau_{n}\}$
\end_inset

, where 
\begin_inset Formula $\tau_{p}=\sigma_{p}^{-2}$
\end_inset

 and 
\begin_inset Formula $\tau_{n}=\sigma_{n}^{-2}$
\end_inset

.
 The variances are expressed in terms of the associated precision for convenienc
e.
 The resulting potential energy function is :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E(\boldsymbol{\theta})\;=\;\tau_{p}\sum_{i=1}^{k}\frac{\theta_{i}^{2}}{2}+\tau_{n}\sum_{c=1}^{n}\frac{(y^{(c)}-f(\xvec^{(c)},\theta))^{2}}{2}
\]

\end_inset

where k is the total number of parameters in the neural network i.e.
 
\begin_inset Formula $\boldsymbol{\theta}=\{\theta_{1},\dots,\theta_{k}\}$
\end_inset

, this includes both the weights and the biases associated with the network.
\end_layout

\begin_layout Standard
It can be noted that this energy function is similar to the error function
 which is minimized for training regularized conventional networks.
 However the objective here is not to minimise the total energy , but rather
 to sample from the canonical distribution represented by the energy.
\end_layout

\begin_layout Standard
We can proceed by introducing the momentum variable, 
\begin_inset Formula $\boldsymbol{p}$
\end_inset

.
 The 
\begin_inset Quotes eld
\end_inset

position
\begin_inset Quotes erd
\end_inset

 variable, 
\begin_inset Formula $\boldsymbol{q}$
\end_inset

 can be associated with the parameters 
\begin_inset Formula $\boldsymbol{\theta}$
\end_inset

 of the network.
 We then use the hybrid Monte Carlo algorithm to generate samples from the
 posterior of the parameters.
 These samples are then used to approximate the integral in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:prediction"

\end_inset

) to make predictions on new data-points.
 
\end_layout

\begin_layout Standard
We plan to use the predictions from the neural network to perform Bayesian
 Optimisation using the GP-LCB acquisition function 
\begin_inset CommandInset citation
LatexCommand cite
key "brochu2010tutorial"

\end_inset

, which is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
a_{LCB}(\xvec) & = & \mu(\xvec)\text{âˆ’}\kappa\sigma(\xvec)
\end{eqnarray}

\end_inset

where 
\begin_inset Formula $\mu(\xvec)$
\end_inset

 is the prediction at point 
\begin_inset Formula $\xvec$
\end_inset

 as given by equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:muLCB-1"

\end_inset

) , and 
\begin_inset Formula $\sigma(\xvec)$
\end_inset

 is the standard deviation at point 
\begin_inset Formula $\xvec$
\end_inset

 calculated in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:sigmaLCB"

\end_inset

).
 
\begin_inset Formula $\kappa$
\end_inset

 is a constant which allows us to explicitly decide the tradeoff between
 exploration and exploitation.
 A high value of 
\begin_inset Formula $\kappa$
\end_inset

 prioritizes exploration by evaluating the function at points with a high
 variance, while a low 
\begin_inset Formula $\kappa$
\end_inset

 prioritizes exploitation by evaluating the function primarily based on
 the prediction mean.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
\mu(\xvec) & = & \int f(\xvec,\boldsymbol{\theta})P(\boldsymbol{\theta,\boldsymbol{\gamma}\,|\,\mathbf{D}})\,d\thevec d\gvec\label{eq:muLCB-1}\\
\sigma(\xvec) & = & \sqrt{\int(f(\xvec,\boldsymbol{\theta})-\mu(\xvec))^{2}P(\boldsymbol{\theta,\boldsymbol{\gamma}\,|\,\mathbf{D}})\,d\thevec d\gvec}\label{eq:sigmaLCB}
\end{eqnarray}

\end_inset

With 
\begin_inset Formula $N$
\end_inset

 samples, from the posterior distribution of the parameters, 
\begin_inset Formula $\{\boldsymbol{\theta_{1}},\dots,\boldsymbol{\theta_{N}}\}$
\end_inset

, we can approximate the required integrals by using MCMC methods to give:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray}
\mu(\xvec) & = & \frac{1}{N}\sum_{i=1}^{N}f(\xvec,\boldsymbol{\theta_{i}})\label{eq:muLCB-MCMC}\\
\sigma(\xvec) & = & \sqrt{\frac{1}{N}\sum_{i=1}^{N}(f(\xvec,\boldsymbol{\theta_{i}})-\mu(\xvec))^{2}}\label{eq:sigmaLCB-MCMC}
\end{eqnarray}

\end_inset

In Bayesian optimisation, to decide the next point to evaluate the function
 on, we need to solve an optimisation problem on the acquisition function.
 For this we require the derivatives of the acquisition function with respect
 to 
\begin_inset Formula $\xvec$
\end_inset

.
 This derivative can be easily expressed in terms of samples from the posterior
 of the neural network.
 
\end_layout

\begin_layout Subsubsection
Verifying correctness
\end_layout

\begin_layout Standard
To verify the correctness of the above implementation, we show some preliminary
 results on a one dimensional synthetic sinusoidal dataset.
 The dataset was generated by evaluating the function in equation (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:synthetic_sinsoidal"

\end_inset

) at 20 random points and adding some Gaussian noise(
\begin_inset Formula $\sigma=0.1$
\end_inset

) to the observations.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f(x)=\sin(7x)+\cos(17x)\;\;\;\;\;\;\;\text{for}\ x\in[-1,1]\label{eq:synthetic_sinsoidal}
\end{equation}

\end_inset

A neural network with 3 hidden layers each of width 50 units was used.
 The hyperbolic tangent (tanh) activation function was used in the neural
 network.
 The HMC sampler was used to draw 5000 samples from the posterior distribution.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:trace_parameters_BNN"

\end_inset

 shows the trace of three randomly chosen parameters from the neural network.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-posterior-parameter"

\end_inset

 shows the histogram of the posterior of one of the parameters (
\begin_inset Formula $\theta_{2501}$
\end_inset

).
 It can be seen that the Markov chains have not converged to a single mode
 and instead move between several modes.
 This is confirmed by the multi-modal nature of the histogram of one of
 the parameters in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-posterior-parameter"

\end_inset

.
 This can be attributed to the large number of modes that are likely to
 be present in the posterior.
 The algorithm is explaining 20 training data-points with about 5000 parameters
 of the neural network.
 Multiple configurations of the parameters can explain the training data
 very well.
 To confirm this, we plot the predictions made by the neural networks represente
d by individual HMC samples.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:samples fit"

\end_inset

 shows the predictions of three well spaced samples from the Markov chain.
 As expected the predictions fit the training points very well, but show
 a significant amount of variation far away from them.
 The predictions of individual samples can then be averaged according to
 equations (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:muLCB-MCMC"

\end_inset

) - (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:sigmaLCB-MCMC"

\end_inset

) to find the predictions of the Bayesian neural network.
 The results are shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-overall-fit_prelim"

\end_inset

, with the credible interval taken to be two standard deviations on either
 side of the mean.
 It can be seen that the predictions follow the true function reasonably
 well.
 The prediction uncertainty is also modelled very well, it is low near the
 training data-points and is higher away from them.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename images/trace.png
	lyxscale 20
	width 50col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\begin_inset Graphics
	filename images/posteriorW251.png
	lyxscale 20
	width 50col%

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50text%"
special "none"
height "1pt"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Trace plots of three randomly chosen parameters of the neural network 
\begin_inset CommandInset label
LatexCommand label
name "fig:trace_parameters_BNN"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \quad{}
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50text%"
special "none"
height "1pt"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The histogram of the posterior of parameter 2501 of the neural network.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:The-posterior-parameter"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \hfill{}
\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/multiple_samples.png
	lyxscale 30
	width 70col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Here, we use HMC to draw three well spaced samples from the posterior distributi
on of the neural network parameters.
 The neural network has three hidden layers with 50 units in each layer
 and uses the tanh activation function.
 The predictions of the neural networks represented by the three samples
 are shown along with the true function and the training data available
 for neural network training.
\begin_inset CommandInset label
LatexCommand label
name "fig:samples fit"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/BNN_simple_fit.png
	lyxscale 20
	width 70col%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
centering
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The overall fit of the neural network, averaged over a large number of samples
 from the neural network.
 The prediction matches the true function reasonably well.
 The uncertainty estimates are also modelled well, they are low near the
 training data-point and high away from them.
 The neural network has three hidden layers with 50 units in each layer
 and uses the tanh activation function.
\begin_inset CommandInset label
LatexCommand label
name "fig:The-overall-fit_prelim"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Maybe talk about Gibbs sampling of hypers, talk about splitting the parameters
 into groups which can be handled separately
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Bayesian Optimisation results
\end_layout

\begin_layout Standard
The Bayesian neural network (BNN) model, implemented above was then used
 to perform Bayesian optimisation.
 The lower confidence bound (LCB) acquisition function was used.
 To illustrate the process of Bayesian optimisation, we show some intermediate
 optimisation results on the one dimensional Forrester function 
\begin_inset CommandInset citation
LatexCommand cite
key "forrester2008engineering"

\end_inset

.
 Its global minima is 
\begin_inset Formula $f(x^{*})\approx-6.02074$
\end_inset

 at 
\begin_inset Formula $x^{*}\approx0.7572$
\end_inset

.
 The function is given by:
\begin_inset Formula 
\begin{equation}
f(x)=(6x-2)^{2}\sin(12x-4)\text{\;\;\;\;\;\;\;\ for}\ x\in[0,1]\label{eq:forrester}
\end{equation}

\end_inset

In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Bayesian-Opt-forrester-fit"

\end_inset

, we show the Bayesian optimisation algorithm optimising the Forrester function.
 We start with four random train points in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Number-of-Tra4"

\end_inset

, then a Bayesian neural network (BNN) model is fit to the data to decide
 the next proposal point based on the acquisition function.
 This is done by using a gradient based approach to minimise the acquisition
 function using the derivatives found earlier.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Number-of-Tra5"

\end_inset

 shows the model after querying the Forrester function at the new proposal
 point (
\begin_inset Formula $x^{p}=0$
\end_inset

).
 Figures 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Number-of-TP8"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Number-of-TP14"

\end_inset

 show the model after a few more function evaluations.
 The model mirrors the true function reasonably well and finds the true
 global minima in a reasonable number of function evaluations.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/v2BNNforresterNtrain4.png
	lyxscale 20
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Number of function evaluations = 4
\begin_inset CommandInset label
LatexCommand label
name "fig:Number-of-Tra4"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/v2BNNforresterNtrain5.png
	lyxscale 20
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Number of function evaluations = 5
\begin_inset CommandInset label
LatexCommand label
name "fig:Number-of-Tra5"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/v2BNNforresterNtrain8.png
	lyxscale 20
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Number of function evaluations = 8
\begin_inset CommandInset label
LatexCommand label
name "fig:Number-of-TP8"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/v2BNNforresterNtrain14.png
	lyxscale 20
	width 50col%

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Number of function evaluations = 14
\begin_inset CommandInset label
LatexCommand label
name "fig:Number-of-TP14"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Using a Bayesian neural network for Bayesian Optimisation on the Forrester
 Function.
 The posterior mean is the averaged prediction from 5000 samples from the
 posterior of the Bayesian neural network.
 The standard deviation of the predictions of these samples was used to
 find the 95% confidence interval(95% C.I).
 The neural network has three hidden layers with 50 units in each layer
 and uses the tanh activation function.
\begin_inset CommandInset label
LatexCommand label
name "fig:Bayesian-Opt-forrester-fit"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/objectiveForresterBestValsBoxLike.png
	lyxscale 20
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Forrester Function 
\begin_inset CommandInset citation
LatexCommand cite
key "forrester2008engineering"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/rosenbrock_2DBestValsBoxLike.png
	lyxscale 20
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Rosenbrock(2D) Function 
\begin_inset CommandInset citation
LatexCommand cite
key "picheny2013benchmark"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/mccormickBestValsBoxLike.png
	lyxscale 20
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
McCormick Function 
\begin_inset CommandInset citation
LatexCommand cite
key "adorio2005mvf"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset space \thinspace{}
\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/sixhumpcamelBestValsBoxLike.png
	lyxscale 20
	width 50col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Six Hump Camel Function 
\begin_inset CommandInset citation
LatexCommand cite
key "molga2005test"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Results of Bayesian Optimisation on some standard test functions.
 Evaluations using a Bayesian network(blue) and a Gaussian Process(green)
 are shown.
 In each sub-figure we are minimizing an objective function.
 The vertical axis represents the running minimum function value.
 The experiments were repeated 50 times to collect reliable statistics.
 The circles represent the median of the runs while the top and bottom lines
 represent the 
\begin_inset Formula $75^{th}$
\end_inset

 and 
\begin_inset Formula $25^{th}$
\end_inset

 percentile respectively.
 The neural network has three hidden layers with 50 units in each layer
 and uses the tanh activation function.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Results-BayesOpt-standard"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Following this we evaluate the performance of Bayesian optimisation on a
 few standard functions.
 The results are compared to those from a Gaussian process(GP) based model.
 The 
\emph on
GPyOpt 
\emph default
library as used in 
\begin_inset CommandInset citation
LatexCommand cite
key "gonzalez2015bayesian"

\end_inset

, was used to get the results for GPs.
 The results are shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Results-BayesOpt-standard"

\end_inset

.
\end_layout

\begin_layout Standard

\series bold
Forrester function : 
\series default
This function has been described by Forrester et.al 
\begin_inset CommandInset citation
LatexCommand cite
key "forrester2008engineering"

\end_inset

.
 Its global minima is 
\begin_inset Formula $f(x^{*})=-6.02074$
\end_inset

 at 
\begin_inset Formula $x^{*}=0.7572$
\end_inset

.
 It is defined on the interval 
\begin_inset Formula $[0,1]$
\end_inset

, and has one another local minima in this interval.
 The Bayesian optimisation process was initialized with two function evaluations
 at random points in the interval.
 The BNN model shows competitive performance to a GP based model.
 
\end_layout

\begin_layout Standard

\series bold
Rosenbrock (2D) function : 
\series default
The Rosenbrock function is a very popular function for evaluating the performanc
e of optimisation algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "dixon1978global"

\end_inset

 .
 The function is uni-modal, and the global minimum lies in a narrow, parabolic
 valley.
 However, even though this valley is easy to find, convergence to the minimum
 is difficult 
\begin_inset CommandInset citation
LatexCommand cite
key "picheny2013benchmark"

\end_inset

.
 We initialise the Bayesian optimisation process with 5 random function
 evaluations.
 Its global minima is 
\begin_inset Formula $f(x1^{*},x2^{*})=0$
\end_inset

 at 
\begin_inset Formula $x1^{*}=1\text{ and }x2^{*}=1$
\end_inset

, it is defined on the set 
\begin_inset Formula $\{(x1,x2):-2.048â‰¤x1â‰¤2.048,âˆ’2.048â‰¤x2â‰¤2.048\}$
\end_inset

.
 The BNN model finds the minima after roughly 7 iterations, the GP based
 model does not always succeed in finding the the optimum point for this
 function.
 
\end_layout

\begin_layout Standard

\series bold
McCormick function : 
\series default
The function is very smooth and uni-modal and is evaluated on the rectangle
 
\begin_inset Formula $\{(x1,x2):-1.5â‰¤x1â‰¤4.0,âˆ’3.0â‰¤x2â‰¤4.0\}$
\end_inset

.
 Its global minima is 
\begin_inset Formula $f(x1^{*},x2^{*})=-1.9133$
\end_inset

 at 
\begin_inset Formula $x1^{*}=-0.54719\text{ and }x2^{*}=-1.54719$
\end_inset

.
 We again start with 5 random function evaluations to initialize the Bayesian
 optimisation process.
 Despite better performance initially, the BNN based model converges at
 a point slightly greater than the global minima, while the GP finds the
 global minima.
 However overall performance remains competitive.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check something might be wrong with this function , we get something below
 the actual minima with GpyOpt.
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
Six Hump Camel function : 
\series default
The function is highly multi-modal having 6 local minima, out of which two
 are also global minima.
 The function is evaluated on the set 
\begin_inset Formula $\{(x1,x2):-3â‰¤x1â‰¤3,âˆ’2â‰¤x2â‰¤2\}$
\end_inset

.
 The global minima are at 
\begin_inset Formula $x1^{*}=-0.0898\text{ \& }x2^{*}=0.7126$
\end_inset

 and at 
\begin_inset Formula $x1^{*}=0.0898\text{ \& }x2^{*}=-0.7126$
\end_inset

 , with 
\begin_inset Formula $f(x1^{*},x2^{*})=-1.0316$
\end_inset

.
 On this function, the GP model performs much better than the BNN model.
 The BNN model gets stuck in a local optima and does not manage to find
 the optima.
 
\end_layout

\begin_layout Section
Conclusions 
\end_layout

\begin_layout Standard
The project aimed at exploring the use of probabilistic models provided
 by Bayesian neural networks to model distributions on functions for Bayesian
 optimisation.
 
\end_layout

\begin_layout Standard
Priors were defined on functions by assuming a Gaussian distribution on
 each of the parameters of the neural network.
 The posterior distribution was found by using the available data from objective
 function evaluations to train the model.
 The targets are assumed to be a single real value which can be modelled
 with a Gaussian noise distribution.
 A hybrid Monte Carlo approach was used to draw samples from the posterior
 distribution of the parameters.
 The samples were used to make a probabilistic model on the predictive distribut
ion of the neural network.
 This distribution over functions was then used to perform Bayesian optimisation
 on the objective function.
 
\end_layout

\begin_layout Standard
The performance of this Bayesian neural network(BNN) based model for Bayesian
 optimisation was then compared to one using a Gaussian process (GP) based
 model on a set of popular benchmark functions.
 The performance is slightly better than GPs on the Rosenbrock function
 and slightly worse on the six hump camel function.
 The performance is very similar on the Forrester function and the McCormick
 function.
 Overall the performance of the BNN based model is competitive with the
 GP based model.
 
\end_layout

\begin_layout Standard
The BNN based model provides much more flexibility than the GP based model
 on the class of functions it can model.
 It also scales linearly with the number of observations allowing optimisation
 of functions which require many evaluations.
 Moreover, the priors on the parameters of the network can be chosen to
 be non Gaussian.
 For instance, using a Cauchy distribution on the parameters can allow the
 modelling of non-smooth functions.
 BNN based models can also potentially exploit the excellent dimensionality
 reduction properties and feature selection properties of neural networks
 to perform Bayesian optimisation in high dimensions.
 These ideas will be more thoroughly explored in future work.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard

\lang english
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "bibliography"
options "bibtotoc,plain"

\end_inset


\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
\start_of_appendix
Risk Assessment Retrospective
\end_layout

\begin_layout Standard
The risk assessment submitted at the start of the project identified frequent
 computer use as the main potential hazard.
 This assessment was accurate and no other hazards were encountered during
 the execution of the project.
 To avoid repetitive stress injury from excessive computer use, frequent
 breaks were taken by the author.
 Several exercises and best practices 
\begin_inset CommandInset citation
LatexCommand cite
key "dugan2011healthy"

\end_inset

 were employed to reduce the risk further.
 If the project is to be carried out again, the risk assessment will remain
 the same.
\end_layout

\end_body
\end_document
